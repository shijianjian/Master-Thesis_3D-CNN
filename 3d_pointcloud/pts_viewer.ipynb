{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data comes from http://web.stanford.edu/~ericyi/project_page/part_annotation/index.html\n",
    "from pyntcloud import PyntCloud\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "if sys.platform == 'darwin':\n",
    "    data_path = os.getcwd() + \"/PartAnnotation\"\n",
    "else:\n",
    "    data_path = os.getcwd() + \"\\\\PartAnnotation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data explorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data comes from http://web.stanford.edu/~ericyi/project_page/part_annotation/index.html\n",
    "\n",
    "Rename the folder into proper class names if you want to see the results properly. It won't affect the results but it is better to see a proper label rather than random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_data(data_path):\n",
    "    \"\"\"\n",
    "    Will read all the data under specific data path\n",
    "    \n",
    "    Return:\n",
    "        cate: a dict which all the names encoded by numbers\n",
    "        label: a dict contains all the number & name mappings.\n",
    "    \"\"\"\n",
    "    cate = {}\n",
    "    label = {}\n",
    "    count = 0\n",
    "    for entry in os.scandir(data_path):\n",
    "        if entry.is_dir():\n",
    "            for pts_data in os.scandir(os.path.join(data_path, entry.name, 'points')):\n",
    "                if count in cate:\n",
    "                    cate.update({count: cate.get(count) + 1})\n",
    "                else:\n",
    "                    cate.update({count: 1})\n",
    "                    label.update({count: entry.name})\n",
    "            count += 1\n",
    "    return cate, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate, label = count_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 4045, 1: 83, 2: 56, 3: 7497, 4: 6778, 5: 73, 6: 797, 7: 424, 8: 2318, 9: 460, 10: 337, 11: 214, 12: 307, 13: 85, 14: 152, 15: 8509}\n",
      "{0: 'airplane', 1: 'bag', 2: 'cap', 3: 'car', 4: 'chair', 5: 'earphone', 6: 'guitar', 7: 'knife', 8: 'lamp', 9: 'laptop', 10: 'motorbike', 11: 'mug', 12: 'pistol', 13: 'rocket', 14: 'skateboard', 15: 'table'}\n"
     ]
    }
   ],
   "source": [
    "print(cate)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAGfCAYAAAD8uyvQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5ec83cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,7))\n",
    "\n",
    "plt.bar(list(cate), height=list(cate.values()))\n",
    "plt.xticks(list(cate), list(label.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imbalance problem\n",
    "\n",
    "Method 1: pick same amount of samples from each class\n",
    "\n",
    "Method 2: Repeat small sample classes 10 times or so.\n",
    "\n",
    "    - Add Gaussian Noise\n",
    "    - Add invariant transformations(shift left, right, rotate, etc.)\n",
    "\n",
    "Method 2 is more preferable. since less variance, more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_data(data_path, max_file_num=None, folder_filter=(None, None)):\n",
    "    \"\"\"\n",
    "    Find file in each folder according to the 'data_path'.\n",
    "    \n",
    "    Giving the max number of files via `max_file_num`, it will read first `max_file_num` in each folder. Read all if there is no enough file inside.\n",
    "    \n",
    "    `folder_filter` is a tuple like (100, 2000) which indicates the number of files will between 100 and 2000.\n",
    "    \"\"\"\n",
    "    \n",
    "    min_th, max_th = folder_filter\n",
    "    if max_file_num is not None and folder_filter is not None:\n",
    "        if min_th is not None:\n",
    "            assert(max_file_num > min_th), \"`max_file_num` should be greater than `\" + min_th + \"` in \" + folder_filter\n",
    "        \n",
    "    data = []\n",
    "    label = []\n",
    "    for entry in os.scandir(data_path):\n",
    "        if entry.is_dir():\n",
    "            target_dir_path = os.path.join(data_path, entry.name, 'points')\n",
    "            path, dirs, files = os.walk(target_dir_path).__next__()\n",
    "            file_count = len(files)\n",
    "            if (min_th is None or file_count >= min_th) and (max_th is None or file_count <= max_th):\n",
    "                count = 0\n",
    "                for pts_data in os.scandir(target_dir_path):\n",
    "                    if (max_file_num is None) or (count < max_file_num):\n",
    "                        data.append(os.path.join(data_path, entry.name, 'points', pts_data.name))\n",
    "                        label.append(entry.name)\n",
    "                        count += 1\n",
    "                    else:\n",
    "                        break\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = find_data(data_path, folder_filter=(2000, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_point_cloud = PyntCloud.from_file(data[120], sep=\" \", header=0, names=[\"x\",\"y\",\"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'table'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(label))\n",
    "label[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pyntcloud_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x5ec9ecf8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_point_cloud.plot(point_size=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "- Rotate\n",
    "- Squeeze\n",
    "- Gaussian Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(pts, axis=0, angle_degree=30):\n",
    "    \"\"\"\n",
    "    Rotate the pts point cloud by a specific angle.\n",
    "    \n",
    "    axis = 0 : rotate around x-axis\n",
    "    axis = 1 : rotate around y-axis\n",
    "    axis = 2 : rotate around z-axis\n",
    "    \n",
    "    angle_degree : how much degree you want to rotate the point cloud.\n",
    "    \n",
    "    Algorithm comes in: https://uk.mathworks.com/matlabcentral/answers/123763-how-to-rotate-entire-3d-data-with-x-y-z-values-along-a-particular-axis-say-x-axis\n",
    "    \"\"\"\n",
    "    if axis == 0: \n",
    "        return rotate_by_x(pts, angle_degree)\n",
    "    if axis == 1: \n",
    "        return rotate_by_y(pts, angle_degree)\n",
    "    if axis == 2: \n",
    "        return rotate_by_z(pts, angle_degree)\n",
    "    \n",
    "def rotate_by_x(pts, angle_degree=30):\n",
    "    import numpy as np\n",
    "    degree = np.deg2rad(angle_degree)\n",
    "    res = np.empty(pts.shape)\n",
    "    for index, point in enumerate(pts):\n",
    "        new_point = np.zeros(3)\n",
    "        new_point[0] = point[0] # x\n",
    "        new_point[1] = point[1]*np.cos(degree) - point[2]*np.sin(degree) # y\n",
    "        new_point[2] = point[1]*np.sin(degree) + point[2]*np.cos(degree) # z\n",
    "        res[index] = new_point\n",
    "        \n",
    "    return res\n",
    "\n",
    "    \n",
    "def rotate_by_y(pts, angle_degree=30):\n",
    "    import numpy as np\n",
    "    degree = np.deg2rad(angle_degree)\n",
    "    res = np.empty(pts.shape)\n",
    "    for index, point in enumerate(pts):\n",
    "        new_point = np.zeros(3)\n",
    "        new_point[0] = point[0]*np.cos(degree) + point[2]*np.sin(degree) # x\n",
    "        new_point[1] = point[1] # y\n",
    "        new_point[2] = point[2]*np.cos(degree) - point[0]*np.sin(degree) # z\n",
    "        res[index] = new_point\n",
    "        \n",
    "    return res\n",
    "\n",
    "    \n",
    "def rotate_by_z(pts, angle_degree=30):\n",
    "    import numpy as np\n",
    "    degree = np.deg2rad(angle_degree)\n",
    "    res = np.empty(pts.shape)\n",
    "    for index, point in enumerate(pts):\n",
    "        new_point = np.zeros(3)\n",
    "        new_point[0] = point[0]*np.cos(degree) - point[1]*np.sin(degree) # x\n",
    "        new_point[1] = point[0]*np.sin(degree) + point[1]*np.cos(degree) # y\n",
    "        new_point[2] = point[2] # z\n",
    "        res[index] = new_point\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(xyz, filename='xyz'):\n",
    "    import os\n",
    "    file = open(os.path.join(os.getcwd(), filename + \".pts\"), \"w\") \n",
    "    \n",
    "    for point in xyz:\n",
    "        st = \"\"\n",
    "        for item in point:\n",
    "            st += str(item) + \" \"\n",
    "        file.write(st.strip() + \"\\n\")\n",
    "\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_point_cloud = rotate(my_point_cloud.xyz, angle_degree=180)\n",
    "write_to_file(rotated_point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pyntcloud_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x614b4978>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotated_point_cloud_file = PyntCloud.from_file(os.path.join(os.getcwd(), \"xyz.pts\"), sep=\" \", header=0, names=[\"x\",\"y\",\"z\"])\n",
    "rotated_point_cloud_file.plot(point_size=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxelize3D(pts, dim=[1,1,1]):\n",
    "    \"\"\"\n",
    "    pts: receives .pts cloud point data. 2D array, arbitary sized X,Y,Z pairs. (We will only take x,y,z into account for now)\n",
    "    dim: dimensioin of output voxelized data\n",
    "    \n",
    "    This function will locate the grid cube and calculate the density of each cube.\n",
    "    The output will be normalized values.\n",
    "    \"\"\"\n",
    "    assert(pts.shape[1]>=3), \"pts file should contain at least x,y,z coordinate\"\n",
    "    assert(len(dim)==3), \"Please provide 3-d grid size like [32,32,32]\"\n",
    "    \n",
    "    # move all the axis to positive area.\n",
    "    minimum_val = [pts[0][0], pts[0][1], pts[0][2]]\n",
    "\n",
    "    # find the smallest \n",
    "    for pair in pts:\n",
    "        if pair[0] < minimum_val[0]:\n",
    "            minimum_val[0] = pair[0]\n",
    "        if pair[1] < minimum_val[1]:\n",
    "            minimum_val[1] = pair[1]\n",
    "        if pair[2] < minimum_val[2]:\n",
    "            minimum_val[2] = pair[2]\n",
    "            \n",
    "    # move it to first quadrant \n",
    "    rectified_pts = np.empty(pts.shape)\n",
    "    for index, pair in enumerate(pts):\n",
    "        point = np.zeros(3)\n",
    "        point[0] = pair[0] - minimum_val[0]\n",
    "        point[1] = pair[1] - minimum_val[1]\n",
    "        point[2] = pair[2] - minimum_val[2]\n",
    "        rectified_pts[index] = point\n",
    "    \n",
    "    # biggest value in each axis \n",
    "    maximum_val = pts[0][0]\n",
    "    \n",
    "    for pair in rectified_pts:\n",
    "        for val in pair:\n",
    "            if val > maximum_val:\n",
    "                maximum_val = val\n",
    "     \n",
    "    # normalize all the axises to (0,1)\n",
    "    normalized_pts = rectified_pts/maximum_val\n",
    "    \n",
    "    x_grid_length = 1/dim[0]\n",
    "    y_grid_length = 1/dim[1]\n",
    "    z_grid_length = 1/dim[2]\n",
    "    \n",
    "    output = np.zeros((dim[0],dim[1],dim[2]))\n",
    "    \n",
    "    epsilon = 0.000000000001 # we will have at least a 1.0 value which will exceed the index of grid\n",
    "    # we can use a relativly small value to escape that to fit our data\n",
    "    \n",
    "    max_volume_size = 0\n",
    "    \n",
    "    for pair in normalized_pts:\n",
    "        x_loc = int(pair[0]/(x_grid_length + epsilon))\n",
    "        y_loc = int(pair[1]/(y_grid_length + epsilon))\n",
    "        z_loc = int(pair[2]/(z_grid_length + epsilon))\n",
    "        if output[x_loc, y_loc, z_loc] is None:\n",
    "            output[x_loc, y_loc, z_loc] = 1\n",
    "        else:\n",
    "            output[x_loc, y_loc, z_loc] += 1\n",
    "        \n",
    "        if output[x_loc, y_loc, z_loc] > max_volume_size:\n",
    "            max_volume_size = output[x_loc, y_loc, z_loc]\n",
    "    \n",
    "    output = output/max_volume_size    \n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./voxel_grid_plot.py\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_voxelgrid(voxelgrid,\n",
    "                   output_name=None,\n",
    "                   cmap=\"Oranges\",\n",
    "                   axis=True,\n",
    "                   width=800,\n",
    "                   height=600):\n",
    "\n",
    "    scaled_shape = voxelgrid.shape\n",
    "\n",
    "    vector = voxelgrid\n",
    "    points = np.argwhere(vector) * scaled_shape\n",
    "\n",
    "    s_m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    rgb = s_m.to_rgba(vector.reshape(-1)[vector.reshape(-1) > 0])\n",
    "\n",
    "    camera_position = points.max(0) + abs(points.max(0))\n",
    "\n",
    "    look = points.mean(0)\n",
    "\n",
    "    if axis:\n",
    "        axis_size = points.ptp() * 1.5\n",
    "    else:\n",
    "        axis_size = 0\n",
    "\n",
    "    placeholders = {}\n",
    "\n",
    "    placeholders[\"POINTS_X_PLACEHOLDER\"] = points[:, 0].tolist()\n",
    "    placeholders[\"POINTS_Y_PLACEHOLDER\"] = points[:, 1].tolist()\n",
    "    placeholders[\"POINTS_Z_PLACEHOLDER\"] = points[:, 2].tolist()\n",
    "\n",
    "    placeholders[\"R_PLACEHOLDER\"] = rgb[:, 0].tolist()\n",
    "    placeholders[\"G_PLACEHOLDER\"] = rgb[:, 1].tolist()\n",
    "    placeholders[\"B_PLACEHOLDER\"] = rgb[:, 2].tolist()\n",
    "\n",
    "    placeholders[\"S_x_PLACEHOLDER\"] = scaled_shape[0]\n",
    "    placeholders[\"S_y_PLACEHOLDER\"] = scaled_shape[1]\n",
    "    placeholders[\"S_z_PLACEHOLDER\"] = scaled_shape[2]\n",
    "\n",
    "    placeholders[\"CAMERA_X_PLACEHOLDER\"] = camera_position[0]\n",
    "    placeholders[\"CAMERA_Y_PLACEHOLDER\"] = camera_position[1]\n",
    "    placeholders[\"CAMERA_Z_PLACEHOLDER\"] = camera_position[2]\n",
    "\n",
    "    placeholders[\"LOOK_X_PLACEHOLDER\"] = look[0]\n",
    "    placeholders[\"LOOK_Y_PLACEHOLDER\"] = look[1]\n",
    "    placeholders[\"LOOK_Z_PLACEHOLDER\"] = look[2]\n",
    "\n",
    "    placeholders[\"AXIS_SIZE_PLACEHOLDER\"] = axis_size\n",
    "\n",
    "    placeholders[\"N_VOXELS_PLACEHOLDER\"] = sum(vector.reshape(-1) > 0)\n",
    "\n",
    "    if output_name is None:\n",
    "        output_name = \"plotVG.html\"\n",
    "\n",
    "    BASE_PATH = os.getcwd()\n",
    "    src = \"{}/{}\".format(BASE_PATH, \"voxelgrid.html\")\n",
    "    dst = \"{}/{}\".format(os.getcwd(), output_name)\n",
    "\n",
    "    with open(src, \"r\") as inp, open(dst, \"w\") as out:\n",
    "        for line in inp:\n",
    "            for key, val in placeholders.items():\n",
    "                if key in line:\n",
    "                    line = line.replace(key, str(val))\n",
    "            out.write(line)\n",
    "\n",
    "    return IFrame(output_name, width=width, height=height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoom in a little bit, seems like some visual bugs inside the code if you have a large set of points\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"plotVG.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x27d41ff98>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Zoom in a little bit, seems like some visual bugs inside the code if you have a large set of points\")\n",
    "vox = voxelize3D(my_point_cloud.xyz, dim=[48,48,48])\n",
    "plot_voxelgrid(vox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_pts(pts, axis=0, percentage=10):\n",
    "    if axis==0:\n",
    "        return squeeze_by_x(pts, percentage)\n",
    "    if axis==1:\n",
    "        return squeeze_by_y(pts, percentage)\n",
    "    if axis==2:\n",
    "        return squeeze_by_z(pts, percentage)\n",
    "    \n",
    "def squeeze_by_x(pts, percentage):\n",
    "    \n",
    "    v = (100-percentage)/100\n",
    "    output = np.empty(pts.shape)\n",
    "    \n",
    "    assert(v>=0 and v<=1), \"Percentage should between 0 and 100\"\n",
    "    \n",
    "    for index, point in enumerate(pts):\n",
    "        output[index] = point\n",
    "        output[index][0] = output[index][0]*v\n",
    "        \n",
    "    return output\n",
    "    \n",
    "def squeeze_by_y(pts, percentage):\n",
    "    \n",
    "    v = (100-percentage)/100\n",
    "    output = np.empty(pts.shape)\n",
    "    \n",
    "    assert(v>=0 and v<=1), \"Percentage should between 0 and 100\"\n",
    "    \n",
    "    for index, point in enumerate(pts):\n",
    "        output[index] = point\n",
    "        output[index][1] = output[index][1]*v\n",
    "        \n",
    "    return output\n",
    "\n",
    "    \n",
    "def squeeze_by_z(pts, percentage):\n",
    "    \n",
    "    v = (100-percentage)/100\n",
    "    output = np.empty(pts.shape)\n",
    "    \n",
    "    assert(v>=0 and v<=1), \"Percentage should between 0 and 100\"\n",
    "    \n",
    "    for index, point in enumerate(pts):\n",
    "        output[index] = point\n",
    "        output[index][2] = output[index][2]*v\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezed_pts = squeeze_pts(my_point_cloud.xyz, axis=1, percentage=30)\n",
    "write_to_file(squeezed_pts, filename=\"sq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pyntcloud_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x611beac8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotated_point_cloud_file = PyntCloud.from_file(os.path.join(os.getcwd(), \"sq.pts\"), sep=\" \", header=0, names=[\"x\",\"y\",\"z\"])\n",
    "rotated_point_cloud_file.plot(point_size=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(pts, noise_percentage=0.05):\n",
    "    \n",
    "    noise_size = int(noise_percentage*len(pts))\n",
    "    \n",
    "    max_x = min_x = pts[0][0]\n",
    "    max_y = min_y = pts[0][1]\n",
    "    max_z = min_z = pts[0][2]\n",
    "    \n",
    "    for point in pts:\n",
    "        if max_x < point[0]:\n",
    "            max_x = point[0]\n",
    "        if max_y < point[1]:\n",
    "            max_y = point[1]\n",
    "        if max_z < point[2]:\n",
    "            max_z = point[2]\n",
    "            \n",
    "        if min_x < point[0]:\n",
    "            min_x = point[0]\n",
    "        if min_y < point[1]:\n",
    "            min_y = point[1]\n",
    "        if min_y < point[2]:\n",
    "            min_y = point[2]\n",
    "            \n",
    "    import numpy as np\n",
    "    \n",
    "    noise_pts = np.empty((noise_size, 3))\n",
    "    noise_x = np.random.randn(noise_size)*(max_x - min_x)/2\n",
    "    noise_y = np.random.randn(noise_size)*(max_y - min_y)/2\n",
    "    noise_z = np.random.randn(noise_size)*(max_z - min_z)/2\n",
    "    \n",
    "    for i, _ in enumerate(range(noise_size)):\n",
    "        pos = np.random.randint(0,len(pts)-1)\n",
    "        noise_pts[i][0] = pts[pos][0] + noise_x[i]\n",
    "        noise_pts[i][1] = pts[pos][1] + noise_y[i]\n",
    "        noise_pts[i][2] = pts[pos][2] + noise_z[i]\n",
    "        \n",
    "    return np.concatenate((pts, noise_pts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_pts = add_noise(my_point_cloud.xyz)\n",
    "write_to_file(noisy_pts, filename=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pyntcloud_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x614c5dd8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_pts_file = PyntCloud.from_file(os.path.join(os.getcwd(), \"no.pts\"), sep=\" \", header=0, names=[\"x\",\"y\",\"z\"])\n",
    "noisy_pts_file.plot(point_size=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noisy voxelized point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"plotVG.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x614c5588>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vox = voxelize3D(noisy_pts, dim=[48,48,48])\n",
    "plot_voxelgrid(vox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PyntCloud.get_filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_cates(labels):\n",
    "    cates = []\n",
    "    for l in labels:\n",
    "        if l not in cates:\n",
    "            cates.append(l)\n",
    "    return cates\n",
    "\n",
    "def data_onehot_encode(labels):\n",
    "    \"\"\"\n",
    "    Recieves an array of labels.\n",
    "    \"\"\"\n",
    "    cates = label_cates(labels)\n",
    "    # one-hot\n",
    "    onehot = []\n",
    "    for l in labels:\n",
    "        x = np.zeros(len(cates))\n",
    "        x[cates.index(l)] = 1.0\n",
    "        onehot.append(x)\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reshape(data):\n",
    "    \"\"\"\n",
    "    Will read and voxelize the data\n",
    "    \"\"\"\n",
    "    x_reshaped = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if i % 20 == 0:\n",
    "            print(\"Process: \", str('{0:.2f}'.format(i/len(data))) + \"%\", end='\\r')\n",
    "        my_point_cloud = PyntCloud.from_file(data[i], sep=\" \", header=0, names=[\"x\",\"y\",\"z\"])\n",
    "        vox = voxelize3D(my_point_cloud.xyz, [32,32,32])\n",
    "        vox_chan = np.array(vox).reshape(vox.shape + (1,))\n",
    "        x_reshaped.append(vox_chan)\n",
    "        \n",
    "    print(\"Process: \", \" 100% \")        \n",
    "    return x_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_swap(data, index_a, index_b):\n",
    "    temp = data[index_a]\n",
    "    data[index_a] = data[index_b]\n",
    "    data[index_b] = temp\n",
    "    return data\n",
    "\n",
    "def data_random_position(data):\n",
    "    import random\n",
    "    return random.randint(0,len(data)-1)\n",
    "\n",
    "def data_shuffling(data, label):\n",
    "    for i in range(len(data)):\n",
    "        target = data_random_position(data)\n",
    "        data = data_swap(data, i, target)\n",
    "        label = data_swap(label, i, target)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data_raw, shuffled_label_raw = data_shuffling(data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process:   100% \n"
     ]
    }
   ],
   "source": [
    "shuffled_data = data_reshape(shuffled_data_raw)\n",
    "shuffled_label = data_onehot_encode(shuffled_label_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classes = label_cates(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 32, 1)\n",
      "[ 1.  0.  0.  0.  0.]\n",
      "5\n",
      "['car', 'table', 'airplane', 'chair', 'lamp']\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_data[100].shape)\n",
    "print(shuffled_label[100])\n",
    "print(len(shuffled_label[100]))\n",
    "print(label_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-bcc3b85ba4c5>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-39-bcc3b85ba4c5>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    if seed not None:\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def cnn_model(x_train_data, label_size, keep_rate=0.7, seed=None):\n",
    "    \n",
    "    if seed not None:\n",
    "        tf.set_random_seed(seed)\n",
    "    \n",
    "    with tf.name_scope(\"layer_a\"):\n",
    "        # conv => 32*32*32\n",
    "        conv1 = tf.layers.conv3d(inputs=x_train_data, filters=16, kernel_size=[3,3,3], padding='same', activation=tf.nn.relu, name=\"conv1\")\n",
    "        # conv => 32*32*32\n",
    "        conv2 = tf.layers.conv3d(inputs=conv1, filters=32, kernel_size=[3,3,3], padding='same', activation=tf.nn.relu, name=\"conv2\")\n",
    "        # pool => 16*16*16\n",
    "        pool3 = tf.layers.max_pooling3d(inputs=conv2, pool_size=[2, 2, 2], strides=2, name=\"pool3\")\n",
    "        \n",
    "    with tf.name_scope(\"layer_b\"):\n",
    "        # conv => 16*16*16\n",
    "        conv4 = tf.layers.conv3d(inputs=pool3, filters=64, kernel_size=[3,3,3], padding='same', activation=tf.nn.relu, name=\"conv4\")\n",
    "        # conv => 16*16*16\n",
    "        conv5 = tf.layers.conv3d(inputs=conv4, filters=128, kernel_size=[3,3,3], padding='same', activation=tf.nn.relu, name=\"conv5\")\n",
    "        # pool => 8*8*8\n",
    "        pool6 = tf.layers.max_pooling3d(inputs=conv5, pool_size=[2, 2, 2], strides=2, name=\"pool6\")\n",
    "        \n",
    "    with tf.name_scope(\"layer_c\"):\n",
    "        # conv => 8*8*8\n",
    "        conv7 = tf.layers.conv3d(inputs=pool6, filters=256, kernel_size=[3,3,3], padding='same', activation=tf.nn.relu, name=\"conv7\")\n",
    "        # conv => 8*8*8\n",
    "        conv8 = tf.layers.conv3d(inputs=conv7, filters=512, kernel_size=[3,3,3], padding='same', activation=tf.nn.relu, name=\"conv8\")\n",
    "        # pool => 4*4*4\n",
    "        pool9 = tf.layers.max_pooling3d(inputs=conv8, pool_size=[2, 2, 2], strides=2, name=\"pool9\")\n",
    "        \n",
    "    with tf.name_scope(\"batch_norm\"):\n",
    "        cnn3d_bn = tf.layers.batch_normalization(inputs=pool9, training=True, name=\"bn\")\n",
    "        \n",
    "    with tf.name_scope(\"fully_con\"):\n",
    "        flattening = tf.reshape(cnn3d_bn, [-1, 4*4*4*512])\n",
    "        dense = tf.layers.dense(inputs=flattening, units=1024, activation=tf.nn.relu, name=\"full_con\")\n",
    "        # (1-keep_rate) is the probability that the node will be kept\n",
    "        dropout = tf.layers.dropout(inputs=dense, rate=keep_rate, training=True, name=\"dropout\")\n",
    "        \n",
    "    with tf.name_scope(\"y_conv\"):\n",
    "        y_conv = tf.layers.dense(inputs=dropout, units=label_size, name=\"y_pred\")\n",
    "    \n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(x_train_data, y_train_data, x_test_data, y_test_data, learning_rate=0.1, keep_rate=0.7, epochs=10, batch_size=128, using_gpu=False):\n",
    "\n",
    "    if using_gpu:\n",
    "        device_name = '/gpu:1' \n",
    "    else:\n",
    "        device_name = '/cpu:0'\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    \n",
    "    with tf.device(device_name):\n",
    "        with tf.name_scope('inputs'):\n",
    "            x_input = tf.placeholder(tf.float32, shape=[None, 32, 32, 32, 1], name=\"x_input\")\n",
    "            y_input = tf.placeholder(tf.float32, shape=[None, len(shuffled_label[0])], name=\"y_input\") \n",
    "\n",
    "        prediction = cnn_model(x_input, len(y_train_data[0]), keep_rate, seed=1)\n",
    "        tf.add_to_collection(\"logits\", prediction)\n",
    "        \n",
    "        with tf.name_scope(\"cross_entropy\"):\n",
    "            cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y_input), name=\"cross_entropy\")\n",
    "                              \n",
    "        with tf.name_scope(\"training\"):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "            tf.add_to_collection(\"optimizer\", optimizer)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_input, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'), name=\"acc\")\n",
    "        \n",
    "   \n",
    "    if using_gpu:\n",
    "        # GPU using BFC\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allocator_type = 'BFC'\n",
    "        sess =  tf.Session(config= config)\n",
    "            \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    import datetime\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    iterations_train = int(len(x_train_data)/batch_size) + 1\n",
    "    iterations_test = int(len(x_test_data)/batch_size) + 1\n",
    "    # run epochs\n",
    "    for epoch in range(epochs):\n",
    "        start_time_epoch = datetime.datetime.now()\n",
    "        print('Epoch', epoch, 'started')\n",
    "        \n",
    "        # mini batch\n",
    "        for itr in range(iterations_train):\n",
    "            mini_batch_x = x_train_data[itr*batch_size: (itr+1)*batch_size]\n",
    "            mini_batch_y = y_train_data[itr*batch_size: (itr+1)*batch_size]\n",
    "            _optimizer, _cost = sess.run([optimizer, cost], feed_dict={x_input: mini_batch_x, y_input: mini_batch_y})\n",
    "            print('\\tLost for', itr + 1, \"/\", iterations_train, _cost, end='\\r')\n",
    "\n",
    "        import os\n",
    "        model_path = os.path.join(os.getcwd(), 'model', 'model')\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, model_path, global_step=epoch)\n",
    "            \n",
    "        acc = 0\n",
    "        # mini batch\n",
    "        for itr in range(iterations_test):\n",
    "            mini_batch_x = x_test_data[itr*batch_size: (itr+1)*batch_size]\n",
    "            mini_batch_y = y_test_data[itr*batch_size: (itr+1)*batch_size]\n",
    "            _acc = sess.run(accuracy, feed_dict={x_input: mini_batch_x, y_input: mini_batch_y})\n",
    "            acc += _acc\n",
    "        \n",
    "        end_time_epoch = datetime.datetime.now()\n",
    "        print('Testing Set Accuracy:',acc/iterations_test, ' Time elapse: ', str(end_time_epoch - start_time_epoch)) \n",
    "\n",
    "    end_time = datetime.datetime.now()\n",
    "    print('Time elapse: ', str(end_time - start_time))\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cross_validation:\n",
    "    \n",
    "    def __init__(self, data, label, fold=5):\n",
    "        self.data = np.asarray(data)\n",
    "        self.label = np.asarray(label)\n",
    "        assert(len(self.data) == len(self.label))\n",
    "        self.fold = fold\n",
    "        self.current_itr = 0;\n",
    "        self.sample_in_fold = int(len(data)/fold)\n",
    "\n",
    "    def next_bunch(self):\n",
    "        \"\"\"\n",
    "        Return x_train, y_train, x_test, y_test\n",
    "        \"\"\"\n",
    "        assert(self.current_itr < self.fold)\n",
    "        start = self.current_itr * self.sample_in_fold\n",
    "        end = (self.current_itr + 1) * self.sample_in_fold\n",
    "        self.current_itr += 1\n",
    "        if start == 0:\n",
    "            return self.data[end:], self.label[end:], self.data[:end], self.label[:end]\n",
    "        if end >= len(self.data):\n",
    "            return self.data[:start], self.label[:start], self.data[start:], self.label[start:]\n",
    "\n",
    "        return np.concatenate((self.data[:start],self.data[end:])), np.concatenate((self.label[:start],self.label[end:])), self.data[start : end], self.label[start : end]\n",
    "\n",
    "    def have_next(self):\n",
    "        if self.current_itr != self.fold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  0.  0.  0.]\n",
      "car\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"plotVG.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x6a5c8320>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_validation(shuffled_data, shuffled_label, fold=5)\n",
    "\n",
    "_x_train, _y_train, _x_test, _y_test = cv.next_bunch()\n",
    "\n",
    "print(_y_train[15])\n",
    "print(label[15])\n",
    "plot_voxelgrid(_x_train[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started\n",
      "Testing Set Accuracy: 0.954623287671  Time elapse:  0:11:39.664970\n",
      "Time elapse:  0:11:39.664970\n"
     ]
    }
   ],
   "source": [
    "cv = cross_validation(shuffled_data, shuffled_label, fold=5)\n",
    "_x_train, _y_train, _x_test, _y_test = cv.next_bunch()\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "train_neural_network(_x_train[:], _y_train[:], _x_test[:], _y_test[:], learning_rate=0.005, batch_size=16, epochs=1, using_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\212606295\\Desktop\\3D-CNN\\3d_pointcloud\\model\\model-0\n",
      "[[ 32.02239227 -11.45599461   2.84584212 -12.32604694   9.59228134]\n",
      " [-34.80514526  26.75932312 -41.11803436   9.54536343  -1.92445326]\n",
      " [  3.51183701  -7.2204814   13.90912628  -4.48680735  -1.25188041]\n",
      " [ 13.23771191  -0.81693602 -10.01169109 -12.27697086   2.12198615]\n",
      " [ -9.64018059   8.09262466 -26.25359726   0.3626669   -1.55951607]\n",
      " [ 45.67315292 -17.78570366 -27.5862484  -15.18876648 -31.46423149]\n",
      " [-12.04114819 -11.15236092  34.9669075  -18.35472488   6.01698351]\n",
      " [ 19.31368256 -11.40389252 -14.10585403  -5.26422787  -1.98093498]\n",
      " [ 26.95075798 -12.83421993 -13.53486633   1.32063317  -7.31890392]\n",
      " [-17.4441967   -1.53520429 -58.22810364  34.15509033  -8.55582047]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "new_graph = tf.Graph()\n",
    "config = tf.ConfigProto(allow_soft_placement=True) # allow passing gpu-trained model to a cpu machine\n",
    "with tf.Session(graph=new_graph, config=config) as sess:\n",
    "\n",
    "    import os\n",
    "    model_fqn = os.path.join(os.getcwd(), 'model', \"model-0\")\n",
    "    saver = tf.train.import_meta_graph(model_fqn + \".meta\")\n",
    "    saver.restore(sess, model_fqn)\n",
    "\n",
    "    model_graph = tf.get_default_graph()\n",
    "    \n",
    "    cv = cross_validation(shuffled_data, shuffled_label, fold=5)\n",
    "    _x_train, _y_train, _x_test, _y_test = cv.next_bunch()\n",
    "\n",
    "    _x_input = model_graph.get_tensor_by_name('inputs/x_input:0')\n",
    "    _y_input = model_graph.get_tensor_by_name('inputs/y_input:0')\n",
    "\n",
    "    acc = model_graph.get_tensor_by_name('acc:0')\n",
    "    logits = tf.get_collection(\"logits\")[0]\n",
    "    \n",
    "    oprimizer = model_graph.get_collection('optimizer')\n",
    "\n",
    "    _ = sess.run(logits, feed_dict={_x_input: _x_test[:10], _y_input: _y_test[:300]})\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

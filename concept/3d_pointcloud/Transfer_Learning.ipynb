{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data comes from http://web.stanford.edu/~ericyi/project_page/part_annotation/index.html\n",
    "from pyntcloud import PyntCloud\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "if sys.platform == 'darwin':\n",
    "    data_path = os.getcwd() + \"/PartAnnotation\"\n",
    "else:\n",
    "    data_path = os.getcwd() + \"\\\\PartAnnotation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_var_names():\n",
    "    all_vars = []\n",
    "    for i in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES):\n",
    "        all_vars.append(i.name)\n",
    "    return all_vars\n",
    "\n",
    "def get_all_placeholders():\n",
    "    return [x for x in tf.get_default_graph().get_operations() if x.type == \"Placeholder\"]\n",
    "\n",
    "def get_all_mean_op():\n",
    "    return [x for x in tf.get_default_graph().get_operations() if x.type == \"Mean\"]\n",
    "\n",
    "def remove_var(var_name, var_set, mode='full_match'):\n",
    "    \"\"\"\n",
    "    mode:\n",
    "        'full_match'\n",
    "        'startswith'\n",
    "    \"\"\"\n",
    "    if mode == 'full_match':\n",
    "        if var_name in var_set:\n",
    "            var_set.remove(var_name)\n",
    "    elif mode == 'startswith':\n",
    "        for idx, val in enumerate(var_set):\n",
    "            if val.startswith(var_name):\n",
    "                var_set.remove(val)\n",
    "    else:\n",
    "        print('Mode not exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\212606295\\Desktop\\3D-CNN\\3d_pointcloud\\trained_model\\model-2\n",
      "['conv1/kernel:0', 'conv1/bias:0', 'conv2/kernel:0', 'conv2/bias:0', 'conv4/kernel:0', 'conv4/bias:0', 'conv5/kernel:0', 'conv5/bias:0', 'conv7/kernel:0', 'conv7/bias:0', 'conv8/kernel:0', 'conv8/bias:0', 'bn/gamma:0', 'bn/beta:0', 'bn/moving_mean:0', 'bn/moving_variance:0', 'full_con/kernel:0', 'full_con/bias:0', 'y_pred/kernel:0', 'y_pred/bias:0', 'training/beta1_power:0', 'training/beta2_power:0', 'conv1/kernel/Adam:0', 'conv1/kernel/Adam_1:0', 'conv1/bias/Adam:0', 'conv1/bias/Adam_1:0', 'conv2/kernel/Adam:0', 'conv2/kernel/Adam_1:0', 'conv2/bias/Adam:0', 'conv2/bias/Adam_1:0', 'conv4/kernel/Adam:0', 'conv4/kernel/Adam_1:0', 'conv4/bias/Adam:0', 'conv4/bias/Adam_1:0', 'conv5/kernel/Adam:0', 'conv5/kernel/Adam_1:0', 'conv5/bias/Adam:0', 'conv5/bias/Adam_1:0', 'conv7/kernel/Adam:0', 'conv7/kernel/Adam_1:0', 'conv7/bias/Adam:0', 'conv7/bias/Adam_1:0', 'conv8/kernel/Adam:0', 'conv8/kernel/Adam_1:0', 'conv8/bias/Adam:0', 'conv8/bias/Adam_1:0', 'bn/gamma/Adam:0', 'bn/gamma/Adam_1:0', 'bn/beta/Adam:0', 'bn/beta/Adam_1:0', 'full_con/kernel/Adam:0', 'full_con/kernel/Adam_1:0', 'full_con/bias/Adam:0', 'full_con/bias/Adam_1:0', 'y_pred/kernel/Adam:0', 'y_pred/kernel/Adam_1:0', 'y_pred/bias/Adam:0', 'y_pred/bias/Adam_1:0']\n",
      "\n",
      "Optimizer [<tf.Operation 'training/Adam' type=NoOp>]\n",
      "\n",
      "Placeholders [<tf.Operation 'inputs/x_input' type=Placeholder>, <tf.Operation 'inputs/y_input' type=Placeholder>]\n",
      "\n",
      "Mean [<tf.Operation 'batch_norm/bn/moments/mean' type=Mean>, <tf.Operation 'batch_norm/bn/moments/variance' type=Mean>, <tf.Operation 'cross_entropy/cross_entropy' type=Mean>, <tf.Operation 'acc' type=Mean>]\n",
      "{'full_con/bias/Adam', 'conv2/bias/Adam_1', 'conv7/bias', 'conv5/bias/Adam', 'bn/beta/Adam', 'conv2/kernel/Adam', 'conv1/kernel/Adam_1', 'y_pred/kernel/Adam_1', 'conv4/bias/Adam_1', 'bn/beta/Adam_1', 'full_con/kernel/Adam', 'conv8/kernel/Adam', 'conv1/bias', 'conv1/bias/Adam_1', 'bn/beta', 'conv2/bias/Adam', 'conv8/bias', 'conv7/bias/Adam', 'conv2/bias', 'conv8/kernel', 'conv4/kernel', 'conv5/bias/Adam_1', 'bn/gamma/Adam', 'full_con/kernel/Adam_1', 'conv1/bias/Adam', 'conv4/kernel/Adam_1', 'bn/gamma/Adam_1', 'bn/moving_mean', 'training/beta1_power', 'training/beta2_power', 'conv7/bias/Adam_1', 'bn/moving_variance', 'y_pred/bias', 'conv2/kernel/Adam_1', 'y_pred/kernel/Adam', 'full_con/bias/Adam_1', 'conv1/kernel/Adam', 'conv4/bias/Adam', 'conv5/kernel/Adam', 'y_pred/bias/Adam', 'y_pred/kernel', 'full_con/kernel', 'conv5/kernel/Adam_1', 'conv8/bias/Adam', 'conv4/bias', 'full_con/bias', 'conv8/bias/Adam_1', 'conv7/kernel/Adam', 'conv2/kernel', 'conv8/kernel/Adam_1', 'conv4/kernel/Adam', 'conv7/kernel', 'conv5/bias', 'conv5/kernel', 'conv1/kernel', 'y_pred/bias/Adam_1', 'conv7/kernel/Adam_1', 'bn/gamma'}\n"
     ]
    }
   ],
   "source": [
    "new_graph = tf.Graph()\n",
    "config = tf.ConfigProto(allow_soft_placement=True) # allow passing gpu-trained model to a cpu machine\n",
    "with tf.Session(graph=new_graph, config=config) as sess:\n",
    "\n",
    "    import os\n",
    "    model_fqn = os.path.join(os.getcwd(), 'trained_model', \"model-2\")\n",
    "    saver = tf.train.import_meta_graph(model_fqn + \".meta\")\n",
    "    saver.restore(sess, model_fqn)\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "    print(get_all_var_names())\n",
    "    print(\"\\nOptimizer\", graph.get_collection(\"optimizer\"))\n",
    "    print(\"\\nPlaceholders\", get_all_placeholders())\n",
    "    print(\"\\nMean\", get_all_mean_op())\n",
    "    previous_vars = {var.op.name for var in tf.global_variables()}\n",
    "#     previous_vars = [var_name for var_name, _ in tf.contrib.framework.list_variables('ckpt')]\n",
    "    print(previous_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxelize3D(pts, dim=[1,1,1]):\n",
    "    \"\"\"\n",
    "    pts: receives .pts cloud point data. 2D array, arbitary sized X,Y,Z pairs. (We will only take x,y,z into account for now)\n",
    "    dim: dimensioin of output voxelized data\n",
    "    \n",
    "    This function will locate the grid cube and calculate the density of each cube.\n",
    "    The output will be normalized values.\n",
    "    \"\"\"\n",
    "    assert(pts.shape[1]>=3), \"pts file should contain at least x,y,z coordinate\"\n",
    "    assert(len(dim)==3), \"Please provide 3-d grid size like [32,32,32]\"\n",
    "    \n",
    "    # move all the axis to positive area.\n",
    "    minimum_val = [pts[0][0], pts[0][1], pts[0][2]]\n",
    "\n",
    "    # find the smallest \n",
    "    for pair in pts:\n",
    "        if pair[0] < minimum_val[0]:\n",
    "            minimum_val[0] = pair[0]\n",
    "        if pair[1] < minimum_val[1]:\n",
    "            minimum_val[1] = pair[1]\n",
    "        if pair[2] < minimum_val[2]:\n",
    "            minimum_val[2] = pair[2]\n",
    "            \n",
    "    # move it to first quadrant \n",
    "    rectified_pts = np.empty(pts.shape)\n",
    "    for index, pair in enumerate(pts):\n",
    "        point = np.zeros(3)\n",
    "        point[0] = pair[0] - minimum_val[0]\n",
    "        point[1] = pair[1] - minimum_val[1]\n",
    "        point[2] = pair[2] - minimum_val[2]\n",
    "        rectified_pts[index] = point\n",
    "    \n",
    "    # biggest value in each axis \n",
    "    maximum_val = pts[0][0]\n",
    "    \n",
    "    for pair in rectified_pts:\n",
    "        for val in pair:\n",
    "            if val > maximum_val:\n",
    "                maximum_val = val\n",
    "     \n",
    "    # normalize all the axises to (0,1)\n",
    "    normalized_pts = rectified_pts/maximum_val\n",
    "    \n",
    "    x_grid_length = 1/dim[0]\n",
    "    y_grid_length = 1/dim[1]\n",
    "    z_grid_length = 1/dim[2]\n",
    "    \n",
    "    output = np.zeros((dim[0],dim[1],dim[2]))\n",
    "    \n",
    "    epsilon = 0.000000000001 # we will have at least a 1.0 value which will exceed the index of grid\n",
    "    # we can use a relativly small value to escape that to fit our data\n",
    "    \n",
    "    max_volume_size = 0\n",
    "    \n",
    "    for pair in normalized_pts:\n",
    "        x_loc = int(pair[0]/(x_grid_length + epsilon))\n",
    "        y_loc = int(pair[1]/(y_grid_length + epsilon))\n",
    "        z_loc = int(pair[2]/(z_grid_length + epsilon))\n",
    "        if output[x_loc, y_loc, z_loc] is None:\n",
    "            output[x_loc, y_loc, z_loc] = 1\n",
    "        else:\n",
    "            output[x_loc, y_loc, z_loc] += 1\n",
    "        \n",
    "        if output[x_loc, y_loc, z_loc] > max_volume_size:\n",
    "            max_volume_size = output[x_loc, y_loc, z_loc]\n",
    "    \n",
    "    output = output/max_volume_size    \n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path, max_file_num=None, dim=[32,32,32]):\n",
    "    data = []\n",
    "    \n",
    "    target_dir_path = os.path.join(data_path, 'points')\n",
    "    path, dirs, files = os.walk(target_dir_path).__next__()\n",
    "    file_count = len(files)\n",
    "    \n",
    "    count = 0\n",
    "    for pts_data in os.scandir(target_dir_path):\n",
    "        if (max_file_num is None) or (count < max_file_num):\n",
    "            _path = os.path.join(data_path, 'points', pts_data.name)\n",
    "            pts = PyntCloud.from_file(_path, sep=\" \", header=0, names=[\"x\",\"y\",\"z\"])\n",
    "            _vox = voxelize3D(pts.xyz, dim=dim)\n",
    "            vox_chan = np.array(_vox).reshape(_vox.shape + (1,))\n",
    "            data.append(vox_chan)\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "                \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_vars(model_path):\n",
    "    \n",
    "    new_graph = tf.Graph()\n",
    "    config = tf.ConfigProto(allow_soft_placement=True) # allow passing gpu-trained model to a cpu machine\n",
    "    \n",
    "    with tf.Session(graph=new_graph, config=config) as sess:\n",
    "        \n",
    "        # Restore model\n",
    "        previous_vars = {var.op.name for var in tf.global_variables()}\n",
    "\n",
    "    return previous_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3543, 32, 32, 32, 1) (3543, 13) [b'pistol' b'pipes' b'rocket' b'knife' b'motorbike' b'mug' b'laptop'\n",
      " b'skateboar' b'backgroun' b'guitar' b'earphone' b'bag' b'cap']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "h5_data = h5py.File(os.path.join(os.getcwd(), 'small_dataset_with_background.h5'), mode='r')\n",
    "\n",
    "data = h5_data.get(\"voxels\")\n",
    "label = h5_data.get(\"labels\")\n",
    "label_ref = h5_data.get(\"label_ref\")\n",
    "\n",
    "print(data.shape, label.shape, label_ref.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def cnn3d_model(x_train_data, label_size, stop_layer=0, keep_rate=0.7, seed=None):\n",
    "    \n",
    "    if seed is not None:\n",
    "        tf.set_random_seed(seed)\n",
    "        \n",
    "    stop_config = np.ones(14, dtype=bool)\n",
    "    for _ in range(stop_layer):\n",
    "        stop_config[_] = False\n",
    "    \n",
    "    with tf.name_scope(\"layer_a\"):\n",
    "        # conv => 32*32*32\n",
    "        conv1 = tf.layers.conv3d(inputs=x_train_data, filters=16, kernel_size=[3,3,3], padding='same',trainable=bool(stop_config[1]), activation=tf.nn.relu, name=\"conv1\", reuse=tf.AUTO_REUSE)\n",
    "        # conv => 32*32*32\n",
    "        conv2 = tf.layers.conv3d(inputs=conv1, filters=32, kernel_size=[3,3,3], padding='same',trainable=bool(stop_config[2]), activation=tf.nn.relu, name=\"conv2\", reuse=tf.AUTO_REUSE)\n",
    "        # pool => 16*16*16\n",
    "        pool3 = tf.layers.max_pooling3d(inputs=conv2, pool_size=[2, 2, 2], strides=2, name=\"pool3\")\n",
    "        \n",
    "    with tf.name_scope(\"layer_b\"):\n",
    "        # conv => 16*16*16\n",
    "        conv4 = tf.layers.conv3d(inputs=pool3, filters=64, kernel_size=[3,3,3], padding='same',trainable=bool(stop_config[4]), activation=tf.nn.relu, name=\"conv4\", reuse=tf.AUTO_REUSE)\n",
    "        # conv => 16*16*16\n",
    "        conv5 = tf.layers.conv3d(inputs=conv4, filters=128, kernel_size=[3,3,3], padding='same',trainable=bool(stop_config[5]), activation=tf.nn.relu, name=\"conv5\", reuse=tf.AUTO_REUSE)\n",
    "        # pool => 8*8*8\n",
    "        pool6 = tf.layers.max_pooling3d(inputs=conv5, pool_size=[2, 2, 2], strides=2, name=\"pool6\")\n",
    "        \n",
    "    with tf.name_scope(\"layer_c\"):\n",
    "        # conv => 8*8*8\n",
    "        conv7 = tf.layers.conv3d(inputs=pool6, filters=256, kernel_size=[3,3,3], padding='same',trainable=bool(stop_config[7]), activation=tf.nn.relu, name=\"conv7\", reuse=tf.AUTO_REUSE)\n",
    "        # conv => 8*8*8\n",
    "        conv8 = tf.layers.conv3d(inputs=conv7, filters=512, kernel_size=[3,3,3], padding='same',trainable=bool(stop_config[8]), activation=tf.nn.relu, name=\"conv8\", reuse=tf.AUTO_REUSE)\n",
    "        # pool => 4*4*4\n",
    "        pool9 = tf.layers.max_pooling3d(inputs=conv8, pool_size=[2, 2, 2], strides=2, name=\"pool9\")\n",
    "        \n",
    "    with tf.name_scope(\"batch_norm\"):\n",
    "        cnn3d_bn = tf.layers.batch_normalization(inputs=pool9, trainable=bool(stop_config[10]), name=\"bn\", reuse=tf.AUTO_REUSE)\n",
    "        \n",
    "    with tf.name_scope(\"fully_con\"):\n",
    "        flattening = tf.reshape(cnn3d_bn, [-1, 4*4*4*512])\n",
    "        dense = tf.layers.dense(inputs=flattening, units=1024, activation=tf.nn.relu, trainable=bool(stop_config[11]), name=\"full_con\", reuse=tf.AUTO_REUSE)\n",
    "        # (1-keep_rate) is the probability that the node will be kept\n",
    "        # training & trainable are different logic\n",
    "        dropout = tf.layers.dropout(inputs=dense, rate=keep_rate, training=bool(stop_config[12]), name=\"dropout\")\n",
    "        \n",
    "    with tf.name_scope(\"y_conv\"):\n",
    "        y_conv = tf.layers.dense(inputs=dropout, units=label_size, name=\"y_pred\", trainable=bool(stop_config[13]), reuse=tf.AUTO_REUSE)\n",
    "    \n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_streaming_metrics(prediction,label,num_classes):\n",
    "\n",
    "    with tf.name_scope(\"test\"):\n",
    "        # Convert (?, num_classes) into (num_classes) 1-D array\n",
    "        label_n = tf.argmax(label, 1)\n",
    "        prediction_n = tf.argmax(prediction, 1)\n",
    "        # Compute a per-batch confusion\n",
    "        batch_confusion = tf.confusion_matrix(label_n, prediction_n, num_classes=num_classes, name='batch_confusion')\n",
    "        # Create an accumulator variable to hold the counts\n",
    "        confusion = tf.Variable(tf.zeros([num_classes,num_classes], dtype=tf.int32), name='confusion')\n",
    "        # Create the update op for doing a \"+=\" accumulation on the batch\n",
    "        confusion_update = confusion.assign(confusion + batch_confusion )\n",
    "        # Cast counts to float so tf.summary.image renormalizes to [0,255]\n",
    "        confusion_image = tf.reshape(tf.cast(confusion, tf.float32), [1, num_classes, num_classes, 1])\n",
    "\n",
    "        tf.summary.image('confusion',confusion_image)\n",
    "\n",
    "    return confusion_update,confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model(n_classes, stop_layer):\n",
    "    with tf.name_scope('inputs'):\n",
    "        x_input = tf.placeholder(tf.float32, shape=[None, 32, 32, 32, 1], name=\"x_input\")\n",
    "        y_input = tf.placeholder(tf.float32, shape=[None, n_classes], name=\"y_input\") \n",
    "\n",
    "    prediction = cnn3d_model(x_input, n_classes, seed=1234, stop_layer=stop_layer, keep_rate=0.5)\n",
    "    tf.add_to_collection(\"logits\", prediction)\n",
    "\n",
    "    with tf.name_scope(\"cross_entropy\"):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y_input), name=\"cross_entropy\")\n",
    "\n",
    "    with tf.name_scope(\"training\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "        tf.add_to_collection(\"optimizer\", optimizer)\n",
    "\n",
    "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_input, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"acc\")\n",
    "\n",
    "    return {'prediction': prediction, 'cost': cost, 'optimizer': optimizer, 'correct': correct, 'accuracy': accuracy, 'x_input': x_input, 'y_input': y_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_layers_from_trained_model(valid_vars, model_path):\n",
    "    previous_vars = get_previous_vars(model_path)\n",
    "    temp = list(previous_vars)[:]\n",
    "    for idx, val in enumerate(valid_vars):\n",
    "        remove_var(val, temp, mode='startswith')\n",
    "    \n",
    "    for idx, val in enumerate(temp):\n",
    "        remove_var(val, previous_vars, mode='full_match')\n",
    "        \n",
    "    return previous_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3543, 32, 32, 32, 1) (3543, 13)\n",
      "{}\n",
      "[<tf.Variable 'conv1/kernel:0' shape=(3, 3, 3, 1, 16) dtype=float32_ref>, <tf.Variable 'conv1/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'conv2/kernel:0' shape=(3, 3, 3, 16, 32) dtype=float32_ref>, <tf.Variable 'conv2/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv4/kernel:0' shape=(3, 3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'conv4/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv5/kernel:0' shape=(3, 3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'conv5/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'conv7/kernel:0' shape=(3, 3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'conv7/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'conv8/kernel:0' shape=(3, 3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'conv8/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/gamma:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/beta:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'full_con/kernel:0' shape=(32768, 1024) dtype=float32_ref>, <tf.Variable 'full_con/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n",
      "\tLost for 155 / 155 0.0797635\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.886860341278\n",
      "\tLost for 155 / 155 0.0464895\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.912979744264\n",
      "\tLost for 155 / 155 0.01568841\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.933768656716\n",
      "\tLost for 155 / 155 0.00961066\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.9375\n",
      "\tLost for 155 / 155 0.00592276\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.935634328358\n",
      "\tLost for 155 / 155 0.01340844\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.940298507463\n",
      "\tLost for 155 / 155 0.00711193\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.940298507463\n",
      "\tLost for 155 / 155 0.01764941\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.933768656716\n",
      "[[ 96   1   0   0   1   0   0   0   1   0   0   0   0]\n",
      " [  0  97   0   0   0   0   0   0   1   0   0   0   0]\n",
      " [  3   0  18   0   1   1   0   0   3   0   0   0   0]\n",
      " [  0   0   0 119   0   0   0   0   1   3   0   0   0]\n",
      " [  0   0   0   0  97   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  66   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 143   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  47   2   0   0   0   0]\n",
      " [  5   2   3   4   6   1   2   4  27   5   3   7   0]\n",
      " [  0   0   0   1   0   0   0   0   0 240   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0  13   0   0]\n",
      " [  0   0   0   0   0   0   0   0   3   1   0  20   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0   1  11]]\n",
      "{}\n",
      "[<tf.Variable 'conv1/kernel:0' shape=(3, 3, 3, 1, 16) dtype=float32_ref>, <tf.Variable 'conv1/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'conv2/kernel:0' shape=(3, 3, 3, 16, 32) dtype=float32_ref>, <tf.Variable 'conv2/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv4/kernel:0' shape=(3, 3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'conv4/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv5/kernel:0' shape=(3, 3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'conv5/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'conv7/kernel:0' shape=(3, 3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'conv7/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'conv8/kernel:0' shape=(3, 3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'conv8/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/gamma:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/beta:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'full_con/kernel:0' shape=(32768, 1024) dtype=float32_ref>, <tf.Variable 'full_con/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n",
      "\tLost for 155 / 155 0.0608626\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.889658848741\n",
      "\tLost for 155 / 155 0.0310288\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.92723880597\n",
      "\tLost for 155 / 155 0.01418961\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.933768656716\n",
      "\tLost for 155 / 155 0.01978281\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.934701492537\n",
      "\tLost for 155 / 155 0.00629619\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.932835820896\n",
      "\tLost for 155 / 155 0.01144924\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.936567164179\n",
      "\tLost for 155 / 155 0.00490109\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.942164179104\n",
      "\tLost for 155 / 155 0.00865146\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.940298507463\n",
      "[[ 96   1   0   0   1   0   0   0   1   0   0   0   0]\n",
      " [  0  97   0   0   0   0   0   0   1   0   0   0   0]\n",
      " [  3   0  18   0   0   1   0   0   4   0   0   0   0]\n",
      " [  0   0   0 121   0   0   0   0   0   2   0   0   0]\n",
      " [  0   0   0   0  97   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  66   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 143   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  48   1   0   0   0   0]\n",
      " [  7   3   5   3   2   1   1   3  33   5   0   6   0]\n",
      " [  0   0   0   2   0   0   0   0   1 238   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   2   0  11   0   0]\n",
      " [  0   0   0   0   0   0   0   0   3   1   0  20   0]\n",
      " [  0   0   0   0   0   0   0   0   3   0   0   1  10]]\n",
      "{}\n",
      "[<tf.Variable 'conv2/kernel:0' shape=(3, 3, 3, 16, 32) dtype=float32_ref>, <tf.Variable 'conv2/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv4/kernel:0' shape=(3, 3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'conv4/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv5/kernel:0' shape=(3, 3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'conv5/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'conv7/kernel:0' shape=(3, 3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'conv7/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'conv8/kernel:0' shape=(3, 3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'conv8/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/gamma:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/beta:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'full_con/kernel:0' shape=(32768, 1024) dtype=float32_ref>, <tf.Variable 'full_con/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n",
      "\tLost for 155 / 155 0.1051546\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.896188699487\n",
      "\tLost for 155 / 155 0.0196675\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.918843283582\n",
      "\tLost for 155 / 155 0.0601643\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.925106609935\n",
      "\tLost for 155 / 155 0.01152225\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.938432835821\n",
      "\tLost for 155 / 155 0.00917881\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.941231343284\n",
      "\tLost for 155 / 155 0.00863683/ 155 0.199186\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.941231343284\n",
      "\tLost for 155 / 155 0.00168511\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.941231343284\n",
      "\tLost for 155 / 155 0.005857959\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.942164179104\n",
      "[[ 98   0   0   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0  97   0   0   0   0   0   0   1   0   0   0   0]\n",
      " [  1   0  19   0   0   1   0   1   4   0   0   0   0]\n",
      " [  0   0   0 121   0   0   0   0   0   2   0   0   0]\n",
      " [  1   0   0   0  95   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0  66   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 143   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  48   1   0   0   0   0]\n",
      " [  6   2   4   2   4   3   1   3  33   5   1   5   0]\n",
      " [  0   0   0   1   0   0   0   0   1 239   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   1   0  12   0   0]\n",
      " [  0   0   0   0   0   0   0   0   3   1   0  20   0]\n",
      " [  0   0   0   0   0   0   0   0   3   0   0   1  10]]\n",
      "{}\n",
      "[<tf.Variable 'conv4/kernel:0' shape=(3, 3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'conv4/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv5/kernel:0' shape=(3, 3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'conv5/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'conv7/kernel:0' shape=(3, 3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'conv7/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'conv8/kernel:0' shape=(3, 3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'conv8/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/gamma:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/beta:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'full_con/kernel:0' shape=(32768, 1024) dtype=float32_ref>, <tf.Variable 'full_con/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLost for 155 / 155 0.1725299\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.895255863667\n",
      "\tLost for 155 / 155 0.0194202\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.926039445756\n",
      "\tLost for 155 / 155 0.0185685\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.930970149254\n",
      "\tLost for 155 / 155 0.01216471\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.9375\n",
      "\tLost for 155 / 155 0.00983221\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.935634328358\n",
      "\tLost for 155 / 155 0.01900679\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.933768656716\n",
      "\tLost for 155 / 155 0.00184199\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.9375\n",
      "\tLost for 155 / 155 0.01331569\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.940298507463\n",
      "[[ 97   1   0   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0  96   0   0   0   0   0   0   2   0   0   0   0]\n",
      " [  2   0  17   0   1   1   0   1   4   0   0   0   0]\n",
      " [  0   0   0 120   0   0   0   0   0   3   0   0   0]\n",
      " [  0   0   0   0  96   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0  66   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 143   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  48   1   0   0   0   0]\n",
      " [  5   2   3   3   3   2   0   4  33   5   2   6   1]\n",
      " [  0   0   0   1   0   0   0   0   0 240   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0  12   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0  22   0]\n",
      " [  0   0   0   0   0   0   0   0   3   0   0   1  10]]\n",
      "{}\n",
      "[<tf.Variable 'conv4/kernel:0' shape=(3, 3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'conv4/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv5/kernel:0' shape=(3, 3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'conv5/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'conv7/kernel:0' shape=(3, 3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'conv7/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'conv8/kernel:0' shape=(3, 3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'conv8/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/gamma:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/beta:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'full_con/kernel:0' shape=(32768, 1024) dtype=float32_ref>, <tf.Variable 'full_con/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n",
      "\tLost for 155 / 155 0.1366063\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.899920042771\n",
      "\tLost for 155 / 155 0.0178108\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.922308102473\n",
      "\tLost for 155 / 155 0.01086262\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.925373134328\n",
      "\tLost for 155 / 155 0.01023943\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.938166311428\n",
      "\tLost for 155 / 155 0.00559863\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.940298507463\n",
      "\tLost for 155 / 155 0.01365695\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.944029850746\n",
      "\tLost for 155 / 155 0.00794597\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.940298507463\n",
      "\tLost for 155 / 155 0.01232259\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.936567164179\n",
      "[[ 98   0   0   0   0   1   0   0   0   0   0   0   0]\n",
      " [  0  97   0   0   0   0   0   0   1   0   0   0   0]\n",
      " [  5   0  16   0   0   1   0   0   4   0   0   0   0]\n",
      " [  0   0   0 119   0   0   0   0   0   4   0   0   0]\n",
      " [  1   0   0   0  96   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  66   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 142   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  48   1   0   0   0   0]\n",
      " [  6   2   3   3   4   3   0   4  31   5   2   6   0]\n",
      " [  0   0   0   1   0   0   0   0   0 240   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0  12   0   0]\n",
      " [  0   0   0   0   0   0   0   0   3   0   0  21   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0   1  11]]\n",
      "{}\n",
      "[<tf.Variable 'conv5/kernel:0' shape=(3, 3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'conv5/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'conv7/kernel:0' shape=(3, 3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'conv7/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'conv8/kernel:0' shape=(3, 3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'conv8/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/gamma:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/beta:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'full_con/kernel:0' shape=(32768, 1024) dtype=float32_ref>, <tf.Variable 'full_con/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n",
      "\tLost for 155 / 155 0.0904049\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.902718550234\n",
      "\tLost for 155 / 155 0.0133751\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.928171641791\n",
      "\tLost for 155 / 155 0.0265708\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.932835820896\n",
      "\tLost for 155 / 155 0.0507779\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.925373134328\n",
      "\tLost for 155 / 155 0.01160935\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.934701492537\n",
      "\tLost for 155 / 155 0.02966853\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.926305970149\n",
      "\tLost for 155 / 155 0.01402373\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.943097014925\n",
      "\tLost for 155 / 155 0.01496224\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.938432835821\n",
      "[[ 96   1   0   0   0   1   0   0   1   0   0   0   0]\n",
      " [  0  96   0   0   0   0   0   0   2   0   0   0   0]\n",
      " [  2   0  19   0   1   0   0   0   4   0   0   0   0]\n",
      " [  0   0   0 116   0   0   0   0   0   7   0   0   0]\n",
      " [  0   0   0   0  97   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  66   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 143   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  47   2   0   0   0   0]\n",
      " [  3   3   3   3   5   1   0   4  36   5   3   3   0]\n",
      " [  0   0   0   1   0   0   0   0   0 240   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   1   0  12   0   0]\n",
      " [  0   0   0   0   0   0   0   0   4   1   0  19   0]\n",
      " [  0   0   0   0   0   0   0   0   3   0   0   1  10]]\n",
      "{}\n",
      "[<tf.Variable 'conv7/kernel:0' shape=(3, 3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'conv7/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'conv8/kernel:0' shape=(3, 3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'conv8/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/gamma:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/beta:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'full_con/kernel:0' shape=(32768, 1024) dtype=float32_ref>, <tf.Variable 'full_con/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n",
      "\tLost for 155 / 155 0.0402264\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.897121535308\n",
      "\tLost for 155 / 155 0.0246999\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.914845415905\n",
      "\tLost for 155 / 155 0.1063396\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.926305970149\n",
      "\tLost for 155 / 155 0.0313342\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.928171641791\n",
      "\tLost for 155 / 155 0.02422244\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.934701492537\n",
      "\tLost for 155 / 155 0.0222339\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.922574626866\n",
      "\tLost for 155 / 155 0.01305152\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.9375\n",
      "\tLost for 155 / 155 0.02507138\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.936567164179\n",
      "[[ 98   0   0   0   0   1   0   0   0   0   0   0   0]\n",
      " [  0  96   0   0   0   0   0   0   2   0   0   0   0]\n",
      " [  3   1  18   0   0   0   0   0   4   0   0   0   0]\n",
      " [  0   0   0 120   0   0   0   0   0   3   0   0   0]\n",
      " [  2   0   0   0  95   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  66   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 143   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  47   2   0   0   0   0]\n",
      " [  5   2   3   2   3   1   0   4  30   7   3   9   0]\n",
      " [  0   0   0   1   0   0   0   0   0 240   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0  12   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0  22   0]\n",
      " [  0   0   0   0   0   0   0   0   3   0   0   1  10]]\n",
      "{}\n",
      "[<tf.Variable 'conv7/kernel:0' shape=(3, 3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'conv7/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'conv8/kernel:0' shape=(3, 3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'conv8/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/gamma:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/beta:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'full_con/kernel:0' shape=(32768, 1024) dtype=float32_ref>, <tf.Variable 'full_con/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLost for 155 / 155 0.0391148\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.895255863667\n",
      "\tLost for 155 / 155 0.0188741\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.911114072622\n",
      "\tLost for 155 / 155 0.0865393\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.926305970149\n",
      "\tLost for 155 / 155 0.0221642\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.934701492537\n",
      "\tLost for 155 / 155 0.05761026\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.922574626866\n",
      "\tLost for 155 / 155 0.03220549\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.929104477612\n",
      "\tLost for 155 / 155 0.01808676\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.92723880597\n",
      "\tLost for 155 / 155 0.02155721\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.934701492537\n",
      "[[ 98   0   0   0   0   1   0   0   0   0   0   0   0]\n",
      " [  0  94   0   0   0   0   0   0   4   0   0   0   0]\n",
      " [  3   0  16   0   1   0   0   2   4   0   0   0   0]\n",
      " [  0   0   0 115   0   0   0   0   0   8   0   0   0]\n",
      " [  1   0   0   0  96   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  66   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 143   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  48   1   0   0   0   0]\n",
      " [  7   2   3   2   2   1   0   4  33   6   1   8   0]\n",
      " [  0   0   0   1   0   0   0   0   0 240   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   3   0  11   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0  22   0]\n",
      " [  0   0   0   0   0   0   0   0   3   0   0   1  10]]\n",
      "{}\n",
      "[<tf.Variable 'conv8/kernel:0' shape=(3, 3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'conv8/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/gamma:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/beta:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'full_con/kernel:0' shape=(32768, 1024) dtype=float32_ref>, <tf.Variable 'full_con/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n",
      "\tLost for 155 / 155 0.0402212\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.908315565159\n",
      "\tLost for 155 / 155 0.0369395\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.915778251726\n",
      "\tLost for 155 / 155 0.0631632\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.924440298507\n",
      "\tLost for 155 / 155 0.0415955\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.933768656716\n",
      "\tLost for 155 / 155 0.0206453\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.9375\n",
      "\tLost for 155 / 155 0.03135269\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.921641791045\n",
      "\tLost for 155 / 155 0.0281314\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.939365671642\n",
      "\tLost for 155 / 155 0.00969481\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.928171641791\n",
      "[[ 98   0   0   0   0   0   0   0   1   0   0   0   0]\n",
      " [  0  96   0   0   0   0   0   0   2   0   0   0   0]\n",
      " [  2   0  18   0   1   0   0   0   4   0   0   0   1]\n",
      " [  0   0   0 118   0   0   0   0   0   5   0   0   0]\n",
      " [  1   0   0   0  95   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0  66   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 142   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  48   1   0   0   0   0]\n",
      " [  4   2   3   4   5   1   0   4  34   5   1   6   0]\n",
      " [  0   0   0   1   0   0   0   0   0 240   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   4   0  10   0   0]\n",
      " [  0   0   0   0   0   0   0   0   4   1   0  19   0]\n",
      " [  0   0   0   0   0   0   0   0   5   0   0   1   8]]\n",
      "{}\n",
      "[<tf.Variable 'bn/gamma:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/beta:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'full_con/kernel:0' shape=(32768, 1024) dtype=float32_ref>, <tf.Variable 'full_con/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n",
      "\tLost for 155 / 155 0.285224/ 155 2.51605 / 155 1.97025 / 155 2.15913 / 155 1.05765 / 155 0.554438 / 155 0.675958140 / 155 0.567816\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.849280384049\n",
      "\tLost for 155 / 155 0.1460042155 0.724489 / 155 0.771016 14 / 155 0.586765\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.88872601292\n",
      "\tLost for 155 / 155 0.1195924155 0.242065/ 155 0.630398 / 155 0.23423 27 / 155 0.562626 / 155 0.598758\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.897787846736\n",
      "\tLost for 155 / 155 0.1324846/ 155 0.384003 / 155 0.510558 / 155 0.366655124 / 155 0.216382\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.900852878592\n",
      "\tLost for 155 / 155 0.0583756/ 155 0.31295460 / 155 0.083779362 / 155 0.245261 / 155 0.212665 90 / 155 0.390896 / 155 0.324018 / 155 0.341449 / 155 0.496067 / 155 0.684258 / 155 0.314655146 / 155 0.474816 / 155 0.0990226/ 155 0.465118\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.91950959501\n",
      "\tLost for 155 / 155 0.0753901 155 0.341608 / 155 0.181889 / 155 0.229534 / 155 0.0997418 / 155 0.0868601 / 155 0.153723 / 155 0.414475 / 155 0.522413\n",
      "\n",
      "\tLost for 66 / 67 67 / 67\n",
      "\n",
      "Test Acc: 0.911380597015\n",
      "\tLost for 155 / 155 0.3503692/ 155 0.230646 / 155 0.367234 43 / 155 0.451141 / 155 0.0513034 / 155 0.59261497 / 155 0.124925 / 155 0.0632372\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.914179104478\n",
      "\tLost for 155 / 155 0.0475454/ 155 0.0539051 / 155 0.529088 27 / 155 0.446998 / 155 0.0555717\n",
      "\n",
      "\tLost for 66 / 67 67 / 67\n",
      "\n",
      "Test Acc: 0.925373134328\n",
      "[[ 98   0   0   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0  96   0   1   0   0   0   0   1   0   0   0   0]\n",
      " [  1   0  18   0   3   0   0   2   2   0   0   0   0]\n",
      " [  0   0   0 120   0   0   0   0   0   3   0   0   0]\n",
      " [  2   0   0   0  94   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0  66   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 143   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  48   1   0   0   0   0]\n",
      " [  4   2   3   5   7   1   2   5  31   5   0   4   0]\n",
      " [  0   0   0   3   0   0   0   0   1 237   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   5   0   8   1   0]\n",
      " [  0   0   0   0   0   0   0   0   5   1   0  18   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0   1  11]]\n",
      "{}\n",
      "[<tf.Variable 'bn/gamma:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bn/beta:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'full_con/kernel:0' shape=(32768, 1024) dtype=float32_ref>, <tf.Variable 'full_con/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n",
      "\tLost for 155 / 155 0.285223155 2.5160510 / 155 1.97025 26 / 155 2.07703 / 155 1.2758432 / 155 1.56013 34 / 155 1.23298 / 155 1.25364/ 155 1.02749 / 155 1.20065 / 155 1.23422 / 155 0.826325\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.849280384049\n",
      "\tLost for 155 / 155 0.1460022155 0.698898 / 155 0.42836355 / 155 0.672083/ 155 0.412149\n",
      "\n",
      "\tLost for 66 / 67 67 / 67\n",
      "\n",
      "Test Acc: 0.88872601292\n",
      "\tLost for 155 / 155 0.1202225155 0.783575 / 155 0.457258 / 155 0.775412 0.165771 / 155 0.362401\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.895922175094\n",
      "\tLost for 155 / 155 0.1259966 155 0.129082 / 155 0.686099 / 155 0.423606 / 155 0.780304 / 155 0.6428653 / 155 0.88000997 / 155 0.297027\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.899920042771\n",
      "\tLost for 155 / 155 0.0554284 155 0.125195 / 155 0.714104 / 155 0.125884133 / 155 0.534925 / 155 0.380774 / 155 0.13216\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.918576759189\n",
      "\tLost for 155 / 155 0.0881062155 0.427952 / 155 0.187139 / 155 0.0791927 / 155 0.18915115 / 155 0.106269 / 155 0.183515 / 155 0.605834 / 155 0.138432 / 155 0.405978 / 155 0.386157 / 155 0.100018 / 155 0.32859 / 155 0.548566\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.915111940299\n",
      "\tLost for 155 / 155 0.0571882 155 0.0870091 / 155 0.0814959 / 155 0.376902 / 155 0.0751797 / 155 0.578929 / 155 0.210626 / 155 0.520716 / 155 0.27582169 / 155 0.7900671 / 155 0.402181/ 155 0.120769 / 155 0.338212 / 155 0.171078 / 155 0.52117 / 155 0.0925378\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.908582089552\n",
      "\tLost for 155 / 155 0.0513074 155 0.643903 / 155 0.31117999 / 155 0.0863279 / 155 0.0532895\n",
      "\n",
      "\tLost for 66 / 6767 / 67\n",
      "\n",
      "Test Acc: 0.92723880597\n",
      "[[ 98   0   0   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0  96   0   1   0   0   0   0   1   0   0   0   0]\n",
      " [  1   0  18   0   3   0   0   2   2   0   0   0   0]\n",
      " [  0   0   0 120   0   0   0   0   0   3   0   0   0]\n",
      " [  2   0   0   0  93   0   0   1   1   0   0   0   0]\n",
      " [  0   0   0   0   0  66   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 141   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  48   1   0   0   0   0]\n",
      " [  4   2   3   6   7   1   2   5  31   4   0   4   0]\n",
      " [  0   0   0   4   0   0   0   0   0 237   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   3   0  10   1   0]\n",
      " [  0   0   0   0   0   0   0   0   3   1   0  20   0]\n",
      " [  0   0   0   0   0   0   0   0   3   0   0   1  10]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "[<tf.Variable 'full_con/kernel:0' shape=(32768, 1024) dtype=float32_ref>, <tf.Variable 'full_con/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n",
      "\tLost for 155 / 155 0.272093 155 2.09445 / 155 1.6993539 / 155 1.30792 / 155 1.2319/ 155 1.06878 / 155 1.00027 / 155 0.865093 / 155 0.517461 / 155 0.476442 / 155 0.542273/ 155 0.366507\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.867004264647\n",
      "\tLost for 155 / 155 0.140182155 0.97313 155 0.649597 / 155 0.649144 / 155 0.390012 / 155 0.624349 / 155 0.92289259 / 155 0.36558 / 155 0.419842 63 / 155 0.646949 / 155 0.79768568 / 155 0.562411 / 155 0.153873 / 155 0.32003 / 155 0.338967/ 155 0.33321 / 155 0.286327/ 155 0.885037 / 155 0.141904/ 155 0.179526 / 155 0.325389/ 155 0.621547 / 155 0.298179 / 155 0.664389/ 155 0.323026 / 155 0.986682 / 155 0.865061 112 / 155 0.823985 / 155 0.693232 124 / 155 0.269996131 / 155 0.803568 / 155 0.373165\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.890325160169\n",
      "\tLost for 155 / 155 0.5713291155 0.270274 / 155 0.902539 / 155 0.6699368 / 155 0.276232 / 155 0.510333 / 155 0.56664215 / 155 0.183329/ 155 0.91145326 / 155 0.717299/ 155 0.587481 / 155 0.555946 / 155 0.509393 / 155 0.278155 / 155 0.383766 / 155 0.309343 / 155 0.14994448 / 155 0.289829 / 155 0.200945 / 155 0.89252555 / 155 0.462368 / 155 0.400478 / 155 0.126403 / 155 0.710752 155 0.405696 / 155 0.365119 / 155 0.186589 / 155 0.3811 / 155 0.0932018 / 155 0.466472 / 155 0.109758 / 155 0.142479/ 155 0.320001 / 155 0.172686 / 155 0.191547 / 155 0.26836 / 155 0.351644 / 155 0.127228 / 155 0.55636 / 155 0.463873 / 155 0.502942 / 155 0.121258\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.908315565159\n",
      "\tLost for 155 / 155 0.1304136 155 0.81729 / 155 0.573208 / 155 0.39708 / 155 0.23352 / 155 0.332052 / 155 0.240648 23 / 155 0.086358625 / 155 0.221771 27 / 155 0.520629 / 155 0.620037 / 155 0.63967233 / 155 0.420594 / 155 0.16277937 / 155 0.358269 / 155 0.672963 / 155 0.450451 / 155 0.695451 / 155 0.398844 / 155 0.207447 / 155 0.891727 / 155 0.654272 / 155 0.208955/ 155 0.27208663 / 155 0.345272 / 155 0.310069/ 155 0.0623409 / 155 0.525032/ 155 0.373616 / 155 0.28692575 / 155 0.165611 / 155 0.389049 / 155 0.10322181 / 155 0.962626 / 155 0.0794211 / 155 0.166564 / 155 0.371494108 / 155 0.137463112 / 155 0.889066 / 155 0.702703 / 155 0.730256 / 155 0.646142 / 155 0.205196 / 155 0.481463 / 155 0.115155 / 155 0.108607\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.906449893517\n",
      "\tLost for 155 / 155 0.0908351 155 0.4610817 / 155 0.211033 / 155 0.13004 / 155 0.0830741 / 155 0.562513 / 155 0.137397 / 155 0.359253155 0.397001 / 155 0.294446 / 155 0.15273788 / 155 0.313806 / 155 0.378688\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.909514925373\n",
      "\tLost for 155 / 155 0.0875872 155 0.15617 / 155 0.191947 / 155 0.668851 / 155 0.111301 / 155 0.8444 / 155 0.321393 / 155 0.489912\n",
      "\n",
      "\tLost for 66 / 67 67 / 67\n",
      "\n",
      "Test Acc: 0.915111940299\n",
      "\tLost for 155 / 155 0.0830896 155 0.294108 / 155 0.556464 / 155 0.117089 / 155 0.666479 / 155 0.189683 / 155 0.259112 / 155 0.206839 / 155 0.0495035 / 155 0.705454 / 155 0.147765 / 155 0.0805551 / 155 0.0414436121 / 155 0.0965831 / 155 0.534692 / 155 0.272275\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.913246268657\n",
      "\tLost for 155 / 155 0.0718964155 0.496276 155 0.43808153 / 155 0.694551 / 155 0.411651 / 155 0.313882 / 155 0.317546 / 155 0.411733\n",
      "\n",
      "\tLost for 66 / 67 67 / 67\n",
      "\n",
      "Test Acc: 0.920708955224\n",
      "[[ 98   0   0   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0  86   0  12   0   0   0   0   0   0   0   0   0]\n",
      " [  1   1  21   0   2   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0 118   0   0   0   0   0   5   0   0   0]\n",
      " [  2   0   1   0  93   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0  64   0   0   0   0   0   0   2]\n",
      " [  0   0   0   0   0   0 142   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  48   1   0   0   0   0]\n",
      " [  4   0   4   5   5   1   2   5  31   5   0   6   1]\n",
      " [  0   0   0   3   0   0   0   0   1 237   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   4   0  10   0   0]\n",
      " [  0   0   0   0   0   0   0   0   7   1   0  16   0]\n",
      " [  0   0   0   0   0   0   0   0   3   0   0   1  10]]\n",
      "{}\n",
      "[<tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n",
      "\tLost for 155 / 155 2.47729/ 155 2.56127 / 155 2.49924\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.407915778347\n",
      "\tLost for 155 / 155 2.39922/ 155 2.46613 / 155 2.40551 / 155 2.4507\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.415378464914\n",
      "\tLost for 155 / 155 2.32942 155 2.4045526 / 155 2.52299 / 155 2.42026\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.423773987302\n",
      "\tLost for 155 / 155 2.27184 155 2.4145457 / 155 2.3861 / 155 2.40338 / 155 2.36949\n",
      "\n",
      "\tLost for 66 / 67 67 / 67\n",
      "\n",
      "Test Acc: 0.430303838048\n",
      "\tLost for 155 / 155 2.20627 155 2.31835 / 155 2.18025 / 155 2.23742\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.428438166407\n",
      "\tLost for 155 / 155 2.15947 155 2.23328 / 155 2.21549/ 155 2.18557\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.438699360436\n",
      "\tLost for 155 / 155 2.10543/ 155 2.2426943 / 155 2.1645255 / 155 2.22342\n",
      "\n",
      "\tLost for 66 / 67 67 / 67\n",
      "\n",
      "Test Acc: 0.448960554466\n",
      "\tLost for 155 / 155 2.06159/ 155 2.19104118 / 155 2.14464\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.454557569392\n",
      "[[  6   1   0   0  14   0   0   0   0  78   0   0   0]\n",
      " [  0  19   0   0   0   0  36   0   0  43   0   0   0]\n",
      " [  0   0   0   0   3   0   1   0   0  22   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 123   0   0   0]\n",
      " [  0   0   0   0  81   0   3   0   0  13   0   0   0]\n",
      " [  0   0   0   0   0   5  61   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 143   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   8   0   0  41   0   0   0]\n",
      " [  0   0   0   0   7   0  28   0   0  34   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 241   0   0   0]\n",
      " [  0   0   0   0   0   0  12   0   0   2   0   0   0]\n",
      " [  0   0   0   0   0   0  16   0   0   8   0   0   0]\n",
      " [  0   0   0   0   0   0  14   0   0   0   0   0   0]]\n",
      "{}\n",
      "[<tf.Variable 'y_pred/kernel:0' shape=(1024, 13) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(13,) dtype=float32_ref>, <tf.Variable 'test/confusion:0' shape=(13, 13) dtype=int32_ref>]\n",
      "\tLost for 155 / 155 2.46534 / 155 2.46918\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.445229211183\n",
      "\tLost for 155 / 155 2.37865/ 155 2.42508 / 155 2.45757 / 155 2.44207\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.451759061929\n",
      "\tLost for 155 / 155 2.30145/ 155 2.39049119 / 155 2.35977145 / 155 2.41008 / 155 2.29421 / 155 2.29529\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.455490405213\n",
      "\tLost for 155 / 155 2.23173155 2.36453 / 155 2.34654\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.461087420138\n",
      "\tLost for 155 / 155 2.16801/ 155 2.31931 11 / 155 2.4340935 / 155 2.216 / 155 2.15343 / 155 2.32159 148 / 155 2.16924\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.463885927601\n",
      "\tLost for 155 / 155 2.10917/ 155 2.21178 / 155 2.36919 / 155 2.17366\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.479744136556\n",
      "\tLost for 155 / 155 2.05437/ 155 2.16966 / 155 2.26348\n",
      "\n",
      "\tLost for 67 / 67\n",
      "\n",
      "Test Acc: 0.497468017153\n",
      "\tLost for 155 / 155 2.00297/ 155 2.06634 / 155 2.01099147 / 155 1.967\n",
      "\n",
      "\tLost for 66 / 67 67 / 67\n",
      "\n",
      "Test Acc: 0.511727079082\n",
      "[[ 11   0   0   0  24   0   0   0   0  64   0   0   0]\n",
      " [  0  31   0   0   0   0  35   0   0  32   0   0   0]\n",
      " [  0   0   0   0   3   0   1   0   0  22   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 123   0   0   0]\n",
      " [  0   0   0   0  91   0   3   0   0   3   0   0   0]\n",
      " [  0   0   0   0   0  29  37   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 143   0   0   0   0   0   0]\n",
      " [  0   0   0   0   6   0   9   0   0  34   0   0   0]\n",
      " [  0   0   0   0   9   0  29   0   0  31   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 241   0   0   0]\n",
      " [  0   0   0   0   0   0  12   0   0   2   0   0   0]\n",
      " [  0   0   0   0   0   0  19   0   0   5   0   0   0]\n",
      " [  0   0   0   0   0   0  14   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_path = os.path.join(os.getcwd(), 'trained_model', 'model-2')\n",
    "\n",
    "layers = ['conv1', 'conv2', 'pool3', 'conv4', 'conv5', 'pool6', 'conv7', 'conv8', 'pool9', 'bn', 'full_con', 'dropout', 'y_pred']\n",
    "\n",
    "learning_rate = 0.0005\n",
    "keep_rate = 0.5\n",
    "batch_size = 16\n",
    "\n",
    "x_ = data[:]\n",
    "y_ = label[:]\n",
    "print(x_.shape, y_.shape)\n",
    "        \n",
    "split_point = int(0.7*len(x_))\n",
    "x_train = x_[:split_point]\n",
    "y_train = y_[:split_point]\n",
    "\n",
    "x_test = x_[split_point:]\n",
    "y_test = y_[split_point:]\n",
    "\n",
    "n_classes = len(y_train[0])\n",
    "\n",
    "device_name = '/gpu:1' \n",
    "\n",
    "for stop_layer in range(14):\n",
    "    with tf.Session(graph=tf.Graph(), config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        with tf.device(device_name):\n",
    "            model = new_model(n_classes, stop_layer)\n",
    "\n",
    "        confusion_update, confusion = _get_streaming_metrics(model['prediction'],model['y_input'],n_classes)\n",
    "        \n",
    "        tf.summary.scalar(\"cross_entropy\", model['cost'])\n",
    "        tf.summary.scalar(\"accuracy\", model['accuracy'])\n",
    "        summary_all = tf.summary.merge_all()\n",
    "\n",
    "        logs_path = os.path.join(os.getcwd(), 'summaries', 'confusion_matrix3')\n",
    "        #suffix\n",
    "        filename_suffix = \"_keep_rate_\"+str(keep_rate)+\"_batch_sizes_\"+str(batch_size)+\"_learning_rates_\"+str(learning_rate)+\"_stop_layer_\"+str(stop_layer)\n",
    "        train_writer = tf.summary.FileWriter(os.path.join(logs_path, 'train'), graph=tf.get_default_graph(), filename_suffix=filename_suffix)\n",
    "        test_writer = tf.summary.FileWriter(os.path.join(logs_path, 'test'), graph=tf.get_default_graph(), filename_suffix=filename_suffix)\n",
    "        summary_op = {'summary': summary_all, 'train_writer': train_writer, 'test_writer': test_writer}\n",
    "\n",
    "        valid_vars = layers[:stop_layer]\n",
    "\n",
    "        restore_vars = remove_layers_from_trained_model(valid_vars, model_path)\n",
    "\n",
    "        restore_map = {variable.op.name : variable for variable in tf.global_variables() if variable.op.name in restore_vars}\n",
    "        print(restore_map)\n",
    "        tf.contrib.framework.init_from_checkpoint(os.path.join(os.getcwd(), 'trained_model', 'model-2'), restore_map)\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        print(tf.trainable_variables())\n",
    "\n",
    "        graph = tf.get_default_graph()\n",
    "        \n",
    "        import math\n",
    "        iterations_all = math.ceil(len(x_)/batch_size)\n",
    "        iterations_train = math.ceil(len(x_train)/batch_size)\n",
    "        iterations_test= math.ceil(len(x_test)/batch_size)\n",
    "\n",
    "        for epoch in range(8):\n",
    "            for itr in range(iterations_train):\n",
    "                mini_batch_x = x_train[itr*batch_size: (itr+1)*batch_size]\n",
    "                mini_batch_y = y_train[itr*batch_size: (itr+1)*batch_size]\n",
    "                _optimizer, _cost, _acc, _summary = sess.run([model['optimizer'], model['cost'], model['accuracy'], summary_op['summary']], feed_dict={model['x_input']: mini_batch_x, model['y_input']: mini_batch_y})\n",
    "                print('\\tLost for', itr+1, \"/\", iterations_train, _cost, end='\\r')\n",
    "\n",
    "                summary_op['train_writer'].add_summary(_summary, epoch*batch_size + itr)\n",
    "                summary_op['train_writer'].flush()\n",
    "                \n",
    "            print('\\n')\n",
    "\n",
    "            acc = 0\n",
    "            for itr in range(iterations_test):\n",
    "                mini_batch_x = x_test[itr*batch_size: (itr+1)*batch_size]\n",
    "                mini_batch_y = y_test[itr*batch_size: (itr+1)*batch_size]\n",
    "                _acc = sess.run(model['accuracy'], feed_dict={model['x_input']: mini_batch_x, model['y_input']: mini_batch_y})\n",
    "                acc += _acc\n",
    "                print('\\tLost for', itr+1, \"/\", iterations_test, end='\\r')\n",
    "\n",
    "            summary = tf.Summary()\n",
    "            summary.value.add(tag=\"Accuracy\", simple_value=acc)\n",
    "            summary_op['test_writer'].add_summary(summary, epoch)\n",
    "            summary_op['test_writer'].flush()\n",
    "            print('\\n')\n",
    "            print('Test Acc:', acc/iterations_test)\n",
    "            \n",
    "        for itr in range(iterations_test):\n",
    "            mini_batch_x = x_test[itr*batch_size: (itr+1)*batch_size]\n",
    "            mini_batch_y = y_test[itr*batch_size: (itr+1)*batch_size]\n",
    "            _conf = sess.run(confusion_update, feed_dict={model['x_input']: mini_batch_x, model['y_input']: mini_batch_y})\n",
    "        print(confusion.eval()) \n",
    "        \n",
    "        summary_op['train_writer'].close()\n",
    "        summary_op['test_writer'].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'laptop', b'motorbike', b'pipes', b'knife', b'mug', b'pistol',\n",
       "       b'guitar', b'skateboar', b'rocket', b'cap', b'earphone', b'bag'],\n",
       "      dtype='|S9')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ref.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAJaCAYAAABwagDsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ef56ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = [[135,   0,   0 ,  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
    " [  0, 104,   0,   0,   0,   2,   0,   1,   1,   0,   0,   0],\n",
    " [  0,   0,  88,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
    " [  0,   0,   0, 109,   0,   2,   4,   0,   0,   0,   0,   0],\n",
    " [  0,   0,   0,   0,  67,   0,   0,   0,   0,   1,   0,   0],\n",
    " [  0,   3,   0,   0,   0,  90,   0,   0,   2,   0,   0,   0],\n",
    " [  0,   0,   0,   4,   0,   0, 247,   0,   0,   0,   0,   0],\n",
    " [  0,   0,   0,   0,   0,   0,   0,  38,   0,   0,   0,   0],\n",
    " [  0,   2,   0,   0,   0,   0,   0,   3,  23,   0,   0,   0],\n",
    " [  0,   0,   0,   0,   1,   0,   0,   0,   0,  14,   0,   0],\n",
    " [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  13,   1],\n",
    " [  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,  30]]\n",
    "\n",
    "tags = ['laptop', 'motorbike', 'pipes', 'knife', 'mug', 'pistol', 'guitar', 'skateboar', 'rocket', 'cap', 'earphone', 'bag']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.xticks(np.arange(0,12), tags, rotation=30)\n",
    "plt.yticks(np.arange(0,12), tags)\n",
    "\n",
    "for i,j in ((x,y) for x in range(len(cm))\n",
    "            for y in range(len(cm[0]))):\n",
    "    if cm[i][j] is not 0:\n",
    "        ax.annotate(str(cm[i][j]),xy=(i,j))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./voxel_grid_plot.py\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_voxelgrid(voxelgrid,\n",
    "                   output_name=None,\n",
    "                   cmap=\"Oranges\",\n",
    "                   axis=True,\n",
    "                   width=800,\n",
    "                   height=600):\n",
    "\n",
    "    scaled_shape = voxelgrid.shape\n",
    "\n",
    "    vector = voxelgrid\n",
    "    points = np.argwhere(vector) * scaled_shape\n",
    "\n",
    "    s_m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    rgb = s_m.to_rgba(vector.reshape(-1)[vector.reshape(-1) > 0])\n",
    "\n",
    "    camera_position = points.max(0) + abs(points.max(0))\n",
    "\n",
    "    look = points.mean(0)\n",
    "\n",
    "    if axis:\n",
    "        axis_size = points.ptp() * 1.5\n",
    "    else:\n",
    "        axis_size = 0\n",
    "\n",
    "    placeholders = {}\n",
    "\n",
    "    placeholders[\"POINTS_X_PLACEHOLDER\"] = points[:, 0].tolist()\n",
    "    placeholders[\"POINTS_Y_PLACEHOLDER\"] = points[:, 1].tolist()\n",
    "    placeholders[\"POINTS_Z_PLACEHOLDER\"] = points[:, 2].tolist()\n",
    "\n",
    "    placeholders[\"R_PLACEHOLDER\"] = rgb[:, 0].tolist()\n",
    "    placeholders[\"G_PLACEHOLDER\"] = rgb[:, 1].tolist()\n",
    "    placeholders[\"B_PLACEHOLDER\"] = rgb[:, 2].tolist()\n",
    "\n",
    "    placeholders[\"S_x_PLACEHOLDER\"] = scaled_shape[0]\n",
    "    placeholders[\"S_y_PLACEHOLDER\"] = scaled_shape[1]\n",
    "    placeholders[\"S_z_PLACEHOLDER\"] = scaled_shape[2]\n",
    "\n",
    "    placeholders[\"CAMERA_X_PLACEHOLDER\"] = camera_position[0]\n",
    "    placeholders[\"CAMERA_Y_PLACEHOLDER\"] = camera_position[1]\n",
    "    placeholders[\"CAMERA_Z_PLACEHOLDER\"] = camera_position[2]\n",
    "\n",
    "    placeholders[\"LOOK_X_PLACEHOLDER\"] = look[0]\n",
    "    placeholders[\"LOOK_Y_PLACEHOLDER\"] = look[1]\n",
    "    placeholders[\"LOOK_Z_PLACEHOLDER\"] = look[2]\n",
    "\n",
    "    placeholders[\"AXIS_SIZE_PLACEHOLDER\"] = axis_size\n",
    "\n",
    "    placeholders[\"N_VOXELS_PLACEHOLDER\"] = sum(vector.reshape(-1) > 0)\n",
    "\n",
    "    if output_name is None:\n",
    "        output_name = \"plotVG.html\"\n",
    "\n",
    "    BASE_PATH = os.getcwd()\n",
    "    src = \"{}/{}\".format(BASE_PATH, \"voxelgrid.html\")\n",
    "    dst = \"{}/{}\".format(os.getcwd(), output_name)\n",
    "\n",
    "    with open(src, \"r\") as inp, open(dst, \"w\") as out:\n",
    "        for line in inp:\n",
    "            for key, val in placeholders.items():\n",
    "                if key in line:\n",
    "                    line = line.replace(key, str(val))\n",
    "            out.write(line)\n",
    "\n",
    "    return IFrame(output_name, width=width, height=height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/shijian/git/3D-CNN/3d_pointcloud/trained_model/model-4\n",
      "(3, 3, 3, 1, 16)\n"
     ]
    }
   ],
   "source": [
    "# one hot indexes\n",
    "# 2: chair , 3: car\n",
    "\n",
    "import os\n",
    "model_path = os.path.join(os.getcwd(), 'trained_model', 'model-4')\n",
    "\n",
    "params = get_model_params(model_path)\n",
    "\n",
    "print(params['conv1_w'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num =7000\n",
    "\n",
    "a = get_data(data_path + \"/airplane\", max_file_num=file_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_padding(target, kernel, stride, padding='SAME'):\n",
    "    # Algorithm comes from https://github.com/tensorflow/tensorflow/commit/a276e0999ab4223ac36d75221028d3e8835c60ae\n",
    "    size, kernelsize, color_channels = get_shapes(target, kernel)\n",
    "    \n",
    "    import math\n",
    "    if padding is 'SAME':\n",
    "        out_width = math.ceil(float(size) / float(stride))\n",
    "        pad_along_width = max((out_width - 1) * stride + kernelsize - size, 0)\n",
    "        pad_left_and_top = pad_along_width // 2\n",
    "        pad_right_and_bottom = pad_along_width - pad_left_and_top\n",
    "        padded_target = zero_padding_3d(target, (int((pad_left_and_top)), int(pad_right_and_bottom)))\n",
    "        \n",
    "    elif padding is 'VALID':\n",
    "        # no padding would be used\n",
    "        out_width = math.floor(float(size - kernelsize) / float(stride) + 1)\n",
    "        border = (out_width-1)*stride + kernelsize\n",
    "        print(out_width, border)\n",
    "        padded_target = target[:border,:border,:border, :]\n",
    "        \n",
    "    else:\n",
    "        raise TypeError('Padding strategy `' + padding + '` not found.')\n",
    "        \n",
    "    print(\"Padded shape\", padded_target.shape)\n",
    "    return padded_target\n",
    "\n",
    "\n",
    "def zero_padding_3d(target, padding=None):\n",
    "    if padding is not None:\n",
    "        target = np.pad(target, [(padding[0], padding[1]), (padding[0], padding[1]), (padding[0], padding[1]), (0,0)], mode='constant')\n",
    "    return target\n",
    "\n",
    "\n",
    "def single_convolve_3d(padded_target_slice, kernel):\n",
    "    _slice = padded_target_slice * kernel\n",
    "    res = np.sum(np.sum(np.sum(np.sum(_slice, axis=0), axis=0),axis=0), axis=0)\n",
    "    return res\n",
    "\n",
    "\n",
    "def convole_3d(padded_target, kernel, kernel_bias, stride):\n",
    "    \n",
    "    size, kernelsize, color_channels = get_shapes(padded_target, kernel)\n",
    "    outsize = get_outsize(size, kernelsize, stride)\n",
    "    filter_num = num_of_filters(kernel)\n",
    "    \n",
    "    res = np.zeros((outsize, outsize, outsize, filter_num))\n",
    "    \n",
    "    for i in range(outsize):\n",
    "        for j in range(outsize):\n",
    "            for k in range(outsize):\n",
    "                for f in range(filter_num):\n",
    "                    i_start = i * stride\n",
    "                    j_start = j * stride\n",
    "                    k_start = k * stride\n",
    "\n",
    "                    padded_target_slice = padded_target[i_start : i_start+kernelsize, j_start : j_start+kernelsize, k_start : k_start+kernelsize, :]\n",
    "                    res[i_start, j_start, k_start, f] = single_convolve_3d(padded_target_slice, kernel[:,:,:,:,f])\n",
    "                    \n",
    "    print(res.shape)\n",
    "    return res + kernel_bias\n",
    "   \n",
    "def max_pool_slice(target_slice):\n",
    "    return np.max(target_slice)\n",
    "\n",
    "def get_shapes(target, kernel):\n",
    "    size = target.shape[0]\n",
    "    color_channels = target.shape[3]\n",
    "    kernelsize = kernel.shape[0]\n",
    "    assert(color_channels == kernel.shape[3]), \"The shape of kernel and input does not match, it must have same number of channels.\"\n",
    "    return size, kernelsize, color_channels\n",
    "\n",
    "def get_outsize(size, kernelsize, stride):\n",
    "    outsize = (size-kernelsize)/stride + 1\n",
    "    assert(outsize == int(outsize)), \"Number of filters must be integer\"\n",
    "    \n",
    "    return int(outsize)\n",
    "\n",
    "def num_of_filters(kernel):\n",
    "    return kernel.shape[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_features(target, kernel, bias=None, stride=1, padding='SAME'):\n",
    "    \n",
    "    size, kernelsize, color_channels = get_shapes(target, kernel)\n",
    "    outsize = get_outsize(size, kernelsize, stride)\n",
    "    filter_num = num_of_filters(kernel)\n",
    "    \n",
    "    padded_target = do_padding(target, kernel, stride)\n",
    "    output = convole_3d(padded_target, kernel, bias, stride)\n",
    "    \n",
    "    print(output.shape)\n",
    "    return output\n",
    "\n",
    "\n",
    "def max_pooling(target, pool_size=2, stride=2):\n",
    "    \n",
    "    size = target.shape[0]\n",
    "    outsize = get_outsize(size, pool_size, stride)\n",
    "    filter_num = target.shape[3]\n",
    "    \n",
    "    output = np.zeros((outsize, outsize, outsize, filter_num))\n",
    "    for i in range(outsize):\n",
    "        for j in range(outsize):\n",
    "            for k in range(outsize):\n",
    "                for f in range(filter_num):\n",
    "                    i_start = i*stride\n",
    "                    j_start = j*stride\n",
    "                    k_start = k*stride\n",
    "                    \n",
    "                    output[i, j, k, f] = max_pool_slice(target[i_start:i_start+2, j_start:j_start+2, k_start:k_start+2, f])\n",
    "                    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded shape (34, 34, 34, 1)\n",
      "(32, 32, 32, 16)\n",
      "(32, 32, 32, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"plotVG.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a190245f8>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_conv = output_features(a[0], params['conv1_w'], params['conv1_b'], stride=1, padding='SAME')\n",
    "plot_voxelgrid(first_conv[:,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded shape (34, 34, 34, 16)\n",
      "(32, 32, 32, 32)\n",
      "(32, 32, 32, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"plotVG.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a19024748>"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_conv = output_features(first_conv, params['conv2_w'], params['conv2_b'], stride=1, padding='SAME')\n",
    "plot_voxelgrid(second_conv[:,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"plotVG.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a17fb1668>"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_pool = max_pooling(second_conv, pool_size=2, stride=2)\n",
    "plot_voxelgrid(third_pool[:,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded shape (18, 18, 18, 32)\n",
      "(16, 16, 16, 64)\n",
      "(16, 16, 16, 64)\n",
      "Padded shape (18, 18, 18, 64)\n",
      "(16, 16, 16, 128)\n",
      "(16, 16, 16, 128)\n"
     ]
    }
   ],
   "source": [
    "forth_conv = output_features(third_pool, params['conv4_w'], params['conv4_b'], stride=1, padding='SAME')\n",
    "fifth_conv = output_features(forth_conv, params['conv5_w'], params['conv5_b'], stride=1, padding='SAME')\n",
    "sixth_pooling = max_pooling(fifth_conv, pool_size=2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"plotVG.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a17f1d748>"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_voxelgrid(sixth_pooling[:,:,:,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded shape (10, 10, 10, 128)\n",
      "(8, 8, 8, 256)\n",
      "(8, 8, 8, 256)\n",
      "Padded shape (10, 10, 10, 256)\n",
      "(8, 8, 8, 512)\n",
      "(8, 8, 8, 512)\n"
     ]
    }
   ],
   "source": [
    "seventh_conv = output_features(sixth_pooling, params['conv7_w'], params['conv7_b'], stride=1, padding='SAME')\n",
    "eighth_conv = output_features(seventh_conv, params['conv8_w'], params['conv8_b'], stride=1, padding='SAME')\n",
    "ninth_pooling = max_pooling(eighth_conv, pool_size=2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_voxelgrid(sixth_pooling[:,:,:,10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
